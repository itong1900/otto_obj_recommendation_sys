{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.77 s, sys: 3.38 s, total: 10.2 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../../allData/validationData/train_meta_data.csv\")\n",
    "df_test = pd.read_csv(\"../../allData/validationData/test_meta_data.csv\")\n",
    "df = pd.concat([df, df_test]).reset_index(drop = True)\n",
    "npz = np.load(\"../../allData/validationData/train_core_data.npz\")\n",
    "npz_test = np.load(\"../../allData/validationData/test_core_data.npz\")\n",
    "aids = np.concatenate([npz['aids'], npz_test['aids']])\n",
    "ts = np.concatenate([npz['ts'], npz_test['ts']])\n",
    "ops = np.concatenate([npz['ops'], npz_test['ops']])\n",
    "\n",
    "df[\"start_idx\"] = df['total_action'].cumsum().shift(1).fillna(0).astype(int)\n",
    "df[\"end_time\"] = ts[df[\"start_idx\"] + df[\"total_action\"] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>total_action</th>\n",
       "      <th>session_start_time</th>\n",
       "      <th>session_end_time</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661103727</td>\n",
       "      <td>0</td>\n",
       "      <td>1661103727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660857067</td>\n",
       "      <td>147</td>\n",
       "      <td>1660857067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660577379</td>\n",
       "      <td>174</td>\n",
       "      <td>1660577379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661109666</td>\n",
       "      <td>187</td>\n",
       "      <td>1661109666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1659304900</td>\n",
       "      <td>413</td>\n",
       "      <td>1659304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368249</th>\n",
       "      <td>12899774</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>171022132</td>\n",
       "      <td>1661723968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368250</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>171022133</td>\n",
       "      <td>1661723970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368251</th>\n",
       "      <td>12899776</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>171022134</td>\n",
       "      <td>1661723972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368252</th>\n",
       "      <td>12899777</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>171022135</td>\n",
       "      <td>1661723976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368253</th>\n",
       "      <td>12899778</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>171022136</td>\n",
       "      <td>1661723983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12368254 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           session  total_action  session_start_time  session_end_time  \\\n",
       "0                0           147          1659304800        1661103727   \n",
       "1                1            27          1659304800        1660857067   \n",
       "2                2            13          1659304800        1660577379   \n",
       "3                3           226          1659304800        1661109666   \n",
       "4                4             3          1659304800        1659304900   \n",
       "...            ...           ...                 ...               ...   \n",
       "12368249  12899774             1          1661723968        1661723968   \n",
       "12368250  12899775             1          1661723970        1661723970   \n",
       "12368251  12899776             1          1661723972        1661723972   \n",
       "12368252  12899777             1          1661723976        1661723976   \n",
       "12368253  12899778             1          1661723983        1661723983   \n",
       "\n",
       "          start_idx    end_time  \n",
       "0                 0  1661103727  \n",
       "1               147  1660857067  \n",
       "2               174  1660577379  \n",
       "3               187  1661109666  \n",
       "4               413  1659304900  \n",
       "...             ...         ...  \n",
       "12368249  171022132  1661723968  \n",
       "12368250  171022133  1661723970  \n",
       "12368251  171022134  1661723972  \n",
       "12368252  171022135  1661723976  \n",
       "12368253  171022136  1661723983  \n",
       "\n",
       "[12368254 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "PARALLEL = 1024\n",
    "LOOKBACK_WINDOW = 100   ## only fit the latest LOOKBACK_WINDOW to train the sim matrix\n",
    "TOPN = 20\n",
    "ACTION_WEIGHTS = np.array([1.0, 2.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def getItemTotalLikes(aids, ops, item_total_likes, action_weights):\n",
    "    \"\"\"\n",
    "    Stores the total like score of itemXXX in item_total_likes, based on action_weights parameter. np.array([X, Y, Z])\n",
    "    \"\"\"\n",
    "    for idx, item in enumerate(aids):\n",
    "        if item not in item_total_likes: \n",
    "            item_total_likes[item] = 0\n",
    "        item_total_likes[item] += action_weights[ops[idx]]   ## TODO: For time decay, consider replace with 1, for iuf keep this. \n",
    "        \n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def getSimScoresSingleRow(pairs_this_row, start_time, start_idx, length, aids, ts, ops, action_weights, mode):\n",
    "    \"\"\"\n",
    "    Get the sim scores of items within single session, can be ran in parallel within each batch. \n",
    "    \"\"\"\n",
    "    max_idx = start_idx + length\n",
    "    min_idx = max(max_idx - LOOKBACK_WINDOW, start_idx)  \n",
    "    for i in range(min_idx, max_idx):\n",
    "        for j in range(i+1, max_idx):\n",
    "            if ts[j] - ts[i] > 2 * 60 * 60: continue  #TODO: try 2h only\n",
    "            if aids[i] == aids[j]: continue\n",
    "            \n",
    "            if mode == \"cosine\":\n",
    "                w_ij = action_weights[ops[j]] \n",
    "                w_ji = action_weights[ops[i]] \n",
    "            elif mode == \"iuf\":  ## penalize users that had lots of actions TODO: consider location weight\n",
    "                if ts[max_idx] - start_time > 24 * 60 * 60:\n",
    "                    special_factor = 0.8\n",
    "                else:\n",
    "                    special_factor = 1.0\n",
    "                \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))\n",
    "                w_ij = special_factor * action_weights[ops[j]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "                w_ji = special_factor * action_weights[ops[i]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "            elif mode == \"time_decay\":\n",
    "                ## calculate some time weights of each item, more weights are given when ts is later. #TODO: try adding (i-j) location weight, exponential weight, 0.5 ** (abs(i-j + 1)), \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                #time_i = 1 + 0.1 ** ((1662328791-ts[i])/(1662328791-1659304800)) #1 + 3 * (ts[i] + start_time - 1659304800) / (1662328791 - 1659304800) #  #(1 - 0.8 *(TEST_END_TS - ts[i]) / TIME_SPAN) ** 0.5 # 0.2~1 #   ## time decay weight for item i \n",
    "                #time_j = 1 + 0.1 ** ((1662328791-ts[j])/(1662328791-1659304800))  # 1 + 3 * (ts[j] + start_time - 1659304800) / (1662328791 - 1659304800) # #  #(1 - 0.8 *(TEST_END_TS - ts[j]) / TIME_SPAN) ** 0.5   # \n",
    "                time_i = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[i])/(1662328791-1659304800)) - 0.6  )))\n",
    "                time_j = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[j])/(1662328791-1659304800)) - 0.6  )))\n",
    "                \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))\n",
    "                \n",
    "                w_ij = action_weights[ops[j]] * loc_weight * time_gap_weight * time_i / math.log1p(length)\n",
    "                w_ji = action_weights[ops[i]] * loc_weight * time_gap_weight * time_j / math.log1p(length)\n",
    "                \n",
    "            pairs_this_row[(aids[i], aids[j])] = w_ij\n",
    "            pairs_this_row[(aids[j], aids[i])] = w_ji\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True, cache=True)\n",
    "def getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, action_weights, total_weights, mode=\"cosine\"):\n",
    "    nrows = len(rows)\n",
    "    pairs_this_batch = [{(0, 0): 0.0 for _ in range(0)} for _ in range(nrows)]\n",
    "    ## get the sim scores of each batch in seperate sub dict in pairs_this_batch\n",
    "    for row_i in nb.prange(nrows):  ## run each row of the batch in parallel\n",
    "        _, start_idx, length, start_time = rows[row_i]\n",
    "        getSimScoresSingleRow(pairs_this_batch[row_i], start_time, start_idx, length, aids, ts, ops, action_weights, mode)\n",
    "    ## merge pairs_this_batch into the fullSimMatrix\n",
    "    for row_i in range(nrows):\n",
    "        for (aid1, aid2), score in pairs_this_batch[row_i].items():\n",
    "            if aid1 not in fullSimMatrix: \n",
    "                fullSimMatrix[aid1] = {0: 0.0 for _ in range(0)}\n",
    "            if aid2 not in fullSimMatrix[aid1]:\n",
    "                fullSimMatrix[aid1][aid2] = 0.0\n",
    "            fullSimMatrix[aid1][aid2] += score\n",
    "    \n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def heap_topk(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure\n",
    "    \"\"\"\n",
    "    dic = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q) for _ in range(len(q))][::-1]\n",
    "    for i in range(len(res)):\n",
    "        dic[res[i][1]] = res[i][0]\n",
    "    \n",
    "    return dic\n",
    "   \n",
    "@nb.jit(nopython = True)\n",
    "def trim_simMatrix_topk(fullSimMatrix, k = 50):\n",
    "    \"\"\"\n",
    "    trim top k items of each \"itemX: {itemY: score1, ...}\" pair in fullSimMatrix based on sim scores. \n",
    "    \"\"\"\n",
    "    for item, item_cnt_dict in fullSimMatrix.items():\n",
    "        fullSimMatrix[item] = heap_topk(item_cnt_dict, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def itemTotalLikeNorm(fullSimMatrix, item_total_likes):\n",
    "    for aid_1, relations in fullSimMatrix.items():\n",
    "        for aid_2, sim_score in relations.items():\n",
    "            fullSimMatrix[aid_1][aid_2] = sim_score / (item_total_likes[aid_1] * item_total_likes[aid_2]) ** 0.1  ## TODO: consider 0.1 or other small number\n",
    "            \n",
    "@nb.jit(nopython=True)\n",
    "def maxNormSimMatrix(fullSimMatrix):\n",
    "    for aid_1, relations in fullSimMatrix.items():\n",
    "        max_num = -np.inf\n",
    "        for _, sim_score in relations.items():\n",
    "            if sim_score > max_num:\n",
    "                max_num = sim_score\n",
    "        ## DEGUG use, delete later\n",
    "        if max_num == 0:\n",
    "            print(aid_1)\n",
    "            print(fullSimMatrix[aid_1])\n",
    "        for aid_2, sim_score in relations.items():\n",
    "#             if max_num == 0:\n",
    "#                 max_num += 0.001\n",
    "            fullSimMatrix[aid_1][aid_2] = sim_score / max_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 s, sys: 782 ms, total: 19.5 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## get the Total Like matrix\n",
    "item_total_likes = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.float64)\n",
    "\n",
    "getItemTotalLikes(aids, ops, item_total_likes, ACTION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 998/12079 [01:57<33:03,  5.59it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1999/12079 [04:54<28:36:17, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3000/12079 [07:01<10:26:13,  4.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3999/12079 [09:09<28:42:24, 12.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4999/12079 [11:19<27:28:43, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 5999/12079 [13:34<13:54:06,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6999/12079 [15:17<9:21:16,  6.63s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 7999/12079 [16:59<4:56:13,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 8999/12079 [18:36<5:39:39,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9999/12079 [20:21<8:16:30, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10999/12079 [21:45<1:24:28,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 12002/12079 [23:02<04:29,  3.50s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12079/12079 [23:04<00:00,  8.72it/s]\n",
      "  8%|▊         | 1000/12079 [02:43<18:45:03,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1999/12079 [05:41<37:34:41, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2999/12079 [08:32<16:21:33,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3998/12079 [10:11<15:43,  8.57it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4999/12079 [13:29<29:19:30, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 5999/12079 [15:42<13:00:53,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6999/12079 [17:39<9:45:01,  6.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 7999/12079 [19:39<8:24:21,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 8999/12079 [21:35<13:20:37, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9999/12079 [23:22<7:57:31, 13.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10999/12079 [24:42<1:21:43,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 11994/12079 [25:07<00:02, 41.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12079/12079 [25:56<00:00,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 25min 19s, sys: 49min 18s, total: 2h 14min 38s\n",
      "Wall time: 52min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "simMatrices = {}   ## store a few different similarity matrices using different scoring system, for different prediction type\n",
    "TRIM_CYCLES = 1000   ## trim full sim matrix every XX batches. \n",
    "MODES_TO_TRAIN = [\"iuf\", \"time_decay\"]\n",
    "\n",
    "for mode in MODES_TO_TRAIN:\n",
    "    ## the nested dict to store full sim matrix, {itemX: {itemY: score, itemZ: score, ...}}\n",
    "    fullSimMatrix = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "    max_idx = len(df)\n",
    "    batch_idx = 1  ## compute sim matrix for PARALLEL # of rows per batch, have a total of max_idx/PARALLEL batches.\n",
    "    for idx in tqdm(range(0, max_idx, PARALLEL)):\n",
    "        rows = df.iloc[idx: min(idx + PARALLEL, max_idx)][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "        getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, ACTION_WEIGHTS, item_total_likes, mode=mode)\n",
    "        batch_idx += 1\n",
    "        if batch_idx % TRIM_CYCLES == 0:\n",
    "            print(\"batch_idx: \", batch_idx)\n",
    "            trim_simMatrix_topk(fullSimMatrix, 100)\n",
    "            gc.collect()\n",
    "            #break\n",
    "\n",
    "    \n",
    "    ## trim top 50 when the training is complete\n",
    "    trim_simMatrix_topk(fullSimMatrix, 80)   ## TODO: make this num small enough to reduce time for normalization\n",
    "    ## normalize the fullSimMatrix with item popularity\n",
    "    itemTotalLikeNorm(fullSimMatrix, item_total_likes)\n",
    "    ## max norm of each score\n",
    "    maxNormSimMatrix(fullSimMatrix)\n",
    "    \n",
    "    simMatrices[mode] = fullSimMatrix\n",
    "    \n",
    "    del fullSimMatrix\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simMatrices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39939f46a179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimMatrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iuf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1517085\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'simMatrices' is not defined"
     ]
    }
   ],
   "source": [
    "simMatrices[\"iuf\"][1517085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1517085, 1563459, 1309446, ...,  548599,  384045,  561560])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def heap_topk_return_list(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure, return a list with top \"cap\" elements with highest score\n",
    "    \"\"\"\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q)[1] for _ in range(len(q))][::-1]\n",
    "    \n",
    "    return res\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def getRealTimeActionWeight(ts_action, ts_start, ts_end, op, seq, length, ACTION_WEIGHTS, TRAIN_START_TS, TEST_END_TS):\n",
    "    \"\"\"\n",
    "    This function returns the real time importance weight of test set session actions\n",
    "    input: \n",
    "        ts_action: ts of the action takes place\n",
    "        ts_start: start_ts of this session\n",
    "        ts_end: end_ts of this session\n",
    "        op: type of the action\n",
    "        seq: seq order this action\n",
    "        length: total # of actions of this session. \n",
    "        \n",
    "    CONSTANTS: \n",
    "    ACTION_WEIGHTS\n",
    "    TRAIN_START_TS\n",
    "    TEST_END_TS\n",
    "    \"\"\"\n",
    "#     overall_time_span = TEST_END_TS - TRAIN_START_TS\n",
    "#     #session_time_span = ts_end - ts_start\n",
    "#     time_to_end_of_session = ts_end - ts_action\n",
    "#     if time_to_end_of_session > 24 * 60 * 60:\n",
    "#         time_weight = 0.3\n",
    "#     else:\n",
    "#         time_weight = max(2**(1 - time_to_end_of_session/3600) - 1, 0.4)\n",
    "    \n",
    "    ## TODO: add time decay \n",
    "    \n",
    "    action_weight = ACTION_WEIGHTS[op]\n",
    "    \n",
    "    sequence_weight = max(2 ** (seq/length) - 1, 0.5) ## floor at 0.1  #np.power(2, np.linspace(seq_weight_const, 1, length))[::-1] - 1\n",
    "\n",
    "    res = action_weight * sequence_weight # * time_weight\n",
    "    \n",
    "    return res\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    ending_idx = starting_idx + length\n",
    "    \n",
    "    candidates = aids[starting_idx: ending_idx][::-1]\n",
    "    candidates_ops = ops[starting_idx: ending_idx][::-1]\n",
    "    \n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "    \n",
    "    if length >= 20:   ## if the user has many actions, recommend based on the itemes it had been interacted with only.\n",
    "        sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates)))[::-1] - 1\n",
    "        for aid, op, w in zip(candidates, candidates_ops, sequence_weight):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            potential_to_recommend[aid] += w * test_ops_weights[op]\n",
    "        result[session] = np.array(heap_topk_return_list(potential_to_recommend, 20)) \n",
    "    else:   ## other wise recommend based on the similar items.\n",
    "        for idx in range(starting_idx, ending_idx):\n",
    "            candidate = aids[idx]\n",
    "            if candidate not in potential_to_recommend:\n",
    "                potential_to_recommend[candidate] = np.inf ## ensure large weights on items had interacted with. \n",
    "        \n",
    "        sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates))) - 1\n",
    "        for idx in range(starting_idx, ending_idx):\n",
    "            candidate = aids[idx] \n",
    "            time_weight = 1 + 0.1 ** ((1662328791-ts[idx])/(1662328791-1659304800))\n",
    "            candidate_realtime_weight = test_ops_weights[ops[idx]] * sequence_weight[idx-starting_idx] * time_weight  #getRealTimeActionWeight(ts[idx], ts[starting_idx], ts[ending_idx], ops[idx], idx-starting_idx+1, length, ACTION_WEIGHTS, TRAIN_START_TS, TEST_END_TS)\n",
    "            ## load the potential items to recommend,\n",
    "            if candidate not in full_sim_matrix: \n",
    "                continue\n",
    "            for similar_item in full_sim_matrix[candidate]:\n",
    "#                 if similar_item in candidates:    ## skip the item if the it's already been interacted\n",
    "#                     continue\n",
    "                if similar_item not in potential_to_recommend:\n",
    "                    potential_to_recommend[similar_item] = 0\n",
    "                potential_to_recommend[similar_item] += full_sim_matrix[candidate][similar_item] * candidate_realtime_weight \n",
    "        result[session] = np.array(heap_topk_return_list(potential_to_recommend, 20))\n",
    "    \n",
    "@nb.jit(nopython=True)\n",
    "def run_inference_parallel(rows, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1742/1742 [04:36<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 8s, sys: 50 s, total: 3min 58s\n",
      "Wall time: 4min 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_iuf = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "result_time_decay = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "    start_row = row_idx\n",
    "    end_row = min(row_idx + PARALLEL, len(df))\n",
    "    rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "    run_inference_parallel(rows, aids, ops, ts, result_iuf, simMatrices[\"iuf\"], ACTION_WEIGHTS)\n",
    "    run_inference_parallel(rows, aids, ops, ts, result_time_decay, simMatrices[\"time_decay\"], ACTION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 44s, sys: 4.53 s, total: 1min 49s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "subs = []\n",
    "op_names = [\"clicks\", \"carts\", \"orders\"]\n",
    "\n",
    "for result, op in zip([result_time_decay, result_iuf, result_iuf], op_names):\n",
    "    sub = pd.DataFrame({\"session_type\": result.keys(), \"labels\": result.values()})\n",
    "    sub.session_type = sub.session_type.astype(str) + f\"_{op}\"\n",
    "    sub.labels = sub.labels.apply(lambda x: \" \".join(x.astype(str)))\n",
    "    subs.append(sub)\n",
    "    \n",
    "submission = pd.concat(subs).reset_index(drop=True)\n",
    "#sub.sort_values(by=[\"session_type\"])  ## optional\n",
    "#submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "submission.to_csv('../../allData/validationData/submission_time_dec_onCarts.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff58dbd0ec383761c792d0b6d4f0a9690d9c9b1bec648659fb440990235d5b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
