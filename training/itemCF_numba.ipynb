{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Collaborative Filtering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.7 s, sys: 2.52 s, total: 9.21 s\n",
      "Wall time: 9.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../../allData/validationData/train_meta_data.csv\")\n",
    "df_test = pd.read_csv(\"../../allData/validationData/test_meta_data.csv\")\n",
    "df = pd.concat([df, df_test]).reset_index(drop = True)\n",
    "npz = np.load(\"../../allData/validationData/train_core_data.npz\")\n",
    "npz_test = np.load(\"../../allData/validationData/test_core_data.npz\")\n",
    "aids = np.concatenate([npz['aids'], npz_test['aids']])\n",
    "ts = np.concatenate([npz['ts'], npz_test['ts']])\n",
    "ops = np.concatenate([npz['ops'], npz_test['ops']])\n",
    "\n",
    "df[\"start_idx\"] = df['total_action'].cumsum().shift(1).fillna(0).astype(int)\n",
    "df[\"end_time\"] = ts[df[\"start_idx\"] + df[\"total_action\"] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>total_action</th>\n",
       "      <th>session_start_time</th>\n",
       "      <th>session_end_time</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661103727</td>\n",
       "      <td>0</td>\n",
       "      <td>1661103727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660857067</td>\n",
       "      <td>147</td>\n",
       "      <td>1660857067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660577379</td>\n",
       "      <td>174</td>\n",
       "      <td>1660577379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661109666</td>\n",
       "      <td>187</td>\n",
       "      <td>1661109666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1659304900</td>\n",
       "      <td>413</td>\n",
       "      <td>1659304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368249</th>\n",
       "      <td>12899774</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>171022132</td>\n",
       "      <td>1661723968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368250</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>171022133</td>\n",
       "      <td>1661723970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368251</th>\n",
       "      <td>12899776</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>171022134</td>\n",
       "      <td>1661723972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368252</th>\n",
       "      <td>12899777</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>171022135</td>\n",
       "      <td>1661723976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12368253</th>\n",
       "      <td>12899778</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>171022136</td>\n",
       "      <td>1661723983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12368254 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           session  total_action  session_start_time  session_end_time  \\\n",
       "0                0           147          1659304800        1661103727   \n",
       "1                1            27          1659304800        1660857067   \n",
       "2                2            13          1659304800        1660577379   \n",
       "3                3           226          1659304800        1661109666   \n",
       "4                4             3          1659304800        1659304900   \n",
       "...            ...           ...                 ...               ...   \n",
       "12368249  12899774             1          1661723968        1661723968   \n",
       "12368250  12899775             1          1661723970        1661723970   \n",
       "12368251  12899776             1          1661723972        1661723972   \n",
       "12368252  12899777             1          1661723976        1661723976   \n",
       "12368253  12899778             1          1661723983        1661723983   \n",
       "\n",
       "          start_idx    end_time  \n",
       "0                 0  1661103727  \n",
       "1               147  1660857067  \n",
       "2               174  1660577379  \n",
       "3               187  1661109666  \n",
       "4               413  1659304900  \n",
       "...             ...         ...  \n",
       "12368249  171022132  1661723968  \n",
       "12368250  171022133  1661723970  \n",
       "12368251  171022134  1661723972  \n",
       "12368252  171022135  1661723976  \n",
       "12368253  171022136  1661723983  \n",
       "\n",
       "[12368254 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training -- Derive ItemCF similarity Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "PARALLEL = 1024\n",
    "LOOKBACK_WINDOW = 100   ## only fit the latest LOOKBACK_WINDOW to train the sim matrix\n",
    "#TOPN = 20\n",
    "ACTION_WEIGHTS = np.array([1.0, 6.0, 3.0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section A: Utils Functions \n",
    "1. Count Item Total likes: The similary score will be normalized by \"Item Total Like Scores\". In theory, popular items should have less weight in simiarity score.\n",
    "2. Trimming function: Helpful managing memoery usage. \n",
    "3. Method for normalization: Mostly item total like normalization, and max norm(make all sim score between 0 and 1) of the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Methods for counting Item Total Likes\n",
    "# ==================================\n",
    "@nb.jit(nopython=True)\n",
    "def getItemTotalLikesNaive(aids, ops, item_total_likes, action_weights):\n",
    "    \"\"\"\n",
    "    Stores the total like score of itemXXX in item_total_likes, based on action_weights parameter. np.array([X, Y, Z])\n",
    "    \"\"\"\n",
    "    for idx, item in enumerate(aids):\n",
    "        if item not in item_total_likes: \n",
    "            item_total_likes[item] = 0\n",
    "        item_total_likes[item] += action_weights[ops[idx]]   ## TODO: For time decay, consider replace with 1, for iuf keep this. \n",
    "\n",
    "# ==================================\n",
    "# Methods for rank and trim the sim score dict\n",
    "# ==================================\n",
    "@nb.jit(nopython = True)\n",
    "def heap_topk(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure\n",
    "    \"\"\"\n",
    "    dic = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q) for _ in range(len(q))][::-1]\n",
    "    for i in range(len(res)):\n",
    "        dic[res[i][1]] = res[i][0]\n",
    "    \n",
    "    return dic\n",
    "   \n",
    "@nb.jit(nopython = True)\n",
    "def trim_simMatrix_topk(fullSimMatrix, k = 50):\n",
    "    \"\"\"\n",
    "    trim top k items of each \"itemX: {itemY: score1, ...}\" pair in fullSimMatrix based on sim scores. \n",
    "    \"\"\"\n",
    "    for item, item_cnt_dict in fullSimMatrix.items():\n",
    "        fullSimMatrix[item] = heap_topk(item_cnt_dict, k)\n",
    "\n",
    "# ==================================\n",
    "# Methods for score normalization\n",
    "# ==================================\n",
    "\n",
    "# @nb.jit(nopython=True)\n",
    "# def itemTotalLikeNorm(fullSimMatrix, item_total_likes):\n",
    "#     for aid_1, relations in fullSimMatrix.items():\n",
    "#         for aid_2, sim_score in relations.items():\n",
    "#             fullSimMatrix[aid_1][aid_2] = sim_score / (item_total_likes[aid_1] * item_total_likes[aid_2]) ** 0.1  ## TODO: consider 0.1 or other small number\n",
    "            \n",
    "@nb.jit(nopython=True)\n",
    "def maxNormSimMatrix(fullSimMatrix):\n",
    "    for aid_1, relations in fullSimMatrix.items():\n",
    "        max_num = -np.inf\n",
    "        for _, sim_score in relations.items():\n",
    "            if sim_score > max_num:\n",
    "                max_num = sim_score\n",
    "        ## DEGUG use, delete later\n",
    "        if max_num == 0:\n",
    "            print(aid_1)\n",
    "            print(fullSimMatrix[aid_1])\n",
    "        for aid_2, sim_score in relations.items():\n",
    "#             if max_num == 0:\n",
    "#                 max_num += 0.001\n",
    "            fullSimMatrix[aid_1][aid_2] = sim_score / max_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section B: Sim Score Computation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@nb.jit(nopython=True)\n",
    "def getSimScoresSingleRow(pairs_this_row, start_time, start_idx, length, aids, ts, ops, item_total_likes, action_weights, mode):\n",
    "    \"\"\"\n",
    "    Get the sim scores of items within single session, can be ran in parallel within each batch. \n",
    "    \"\"\"\n",
    "    max_idx = start_idx + length\n",
    "    min_idx = max(max_idx - LOOKBACK_WINDOW, start_idx)  \n",
    "    for i in range(min_idx, max_idx):\n",
    "        for j in range(i+1, max_idx):\n",
    "            if ts[j] - ts[i] > 2 * 60 * 60: continue  #TODO: try 2h only\n",
    "            if aids[i] == aids[j]: continue\n",
    "            \n",
    "            if mode == \"cosine\":\n",
    "                w_ij = action_weights[ops[j]] \n",
    "                w_ji = action_weights[ops[i]] \n",
    "            elif mode == \"iuf\":  ## penalize users that had lots of actions TODO: consider location weight\n",
    "                if ts[max_idx] - start_time > 24 * 60 * 60:\n",
    "                    special_factor = 0.8\n",
    "                else:\n",
    "                    special_factor = 1.0\n",
    "                \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))  \n",
    "                w_ij = special_factor * action_weights[ops[j]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "                w_ji = special_factor * action_weights[ops[i]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "            elif mode == \"time_decay\":\n",
    "                ## calculate some time weights of each item, more weights are given when ts is later. #TODO: try adding (i-j) location weight, exponential weight, 0.5 ** (abs(i-j + 1)), \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                #time_i = 1 + 0.1 ** ((1662328791-ts[i])/(1662328791-1659304800)) #1 + 3 * (ts[i] + start_time - 1659304800) / (1662328791 - 1659304800) #  #(1 - 0.8 *(TEST_END_TS - ts[i]) / TIME_SPAN) ** 0.5 # 0.2~1 #   ## time decay weight for item i \n",
    "                #time_j = 1 + 0.1 ** ((1662328791-ts[j])/(1662328791-1659304800))  # 1 + 3 * (ts[j] + start_time - 1659304800) / (1662328791 - 1659304800) # #  #(1 - 0.8 *(TEST_END_TS - ts[j]) / TIME_SPAN) ** 0.5   # \n",
    "                time_i = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[i])/(1662328791-1659304800)) - 0.6  )))\n",
    "                time_j = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[j])/(1662328791-1659304800)) - 0.6  )))\n",
    "                \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))  \n",
    "                \n",
    "                w_ij = action_weights[ops[j]] * loc_weight * time_gap_weight * time_i / math.log1p(length)\n",
    "                w_ji = action_weights[ops[i]] * loc_weight * time_gap_weight * time_j / math.log1p(length)\n",
    "                \n",
    "            pairs_this_row[(aids[i], aids[j])] = w_ij / (item_total_likes[aids[i]] * item_total_likes[aids[j]]) ** 0.1\n",
    "            pairs_this_row[(aids[j], aids[i])] = w_ji / (item_total_likes[aids[i]] * item_total_likes[aids[j]]) ** 0.1\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True, cache=True)\n",
    "def getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, action_weights, item_total_likes, mode=\"cosine\"):\n",
    "    nrows = len(rows)\n",
    "    pairs_this_batch = [{(0, 0): 0.0 for _ in range(0)} for _ in range(nrows)]\n",
    "    ## get the sim scores of each batch in seperate sub dict in pairs_this_batch\n",
    "    for row_i in nb.prange(nrows):  ## run each row of the batch in parallel\n",
    "        _, start_idx, length, start_time = rows[row_i]\n",
    "        getSimScoresSingleRow(pairs_this_batch[row_i], start_time, start_idx, length, aids, ts, ops, item_total_likes, action_weights, mode)\n",
    "    ## merge pairs_this_batch into the fullSimMatrix\n",
    "    for row_i in range(nrows):\n",
    "        for (aid1, aid2), score in pairs_this_batch[row_i].items():\n",
    "            if aid1 not in fullSimMatrix: \n",
    "                fullSimMatrix[aid1] = {0: 0.0 for _ in range(0)}\n",
    "            if aid2 not in fullSimMatrix[aid1]:\n",
    "                fullSimMatrix[aid1][aid2] = 0.0\n",
    "            fullSimMatrix[aid1][aid2] += score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section C: Train the similarity matrices\n",
    "1. Derive the total like score first\n",
    "2. Train 2 similarity matrices, one using iuf(Inverse User Frequence), the other using time_decay method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 746 ms, total: 22.4 s\n",
      "Wall time: 22.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## get the Total Like matrix\n",
    "item_total_likes = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.float64)\n",
    "\n",
    "getItemTotalLikesNaive(aids, ops, item_total_likes, ACTION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 998/12079 [01:20<16:47, 11.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1997/12079 [03:28<16:12, 10.36it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3000/12079 [05:16<17:17:54,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3999/12079 [07:02<22:53:23, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4999/12079 [08:45<10:42:08,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 6000/12079 [10:25<9:45:51,  5.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7000/12079 [12:00<11:33:27,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 7999/12079 [13:33<7:00:14,  6.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 8999/12079 [15:03<5:22:14,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9999/12079 [16:33<7:15:37, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10994/12079 [17:46<00:24, 43.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 11999/12079 [18:50<15:55, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12079/12079 [18:52<00:00, 10.66it/s]\n",
      "  8%|▊         | 999/12079 [02:22<22:39:07,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2000/12079 [04:50<19:46:35,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2998/12079 [07:10<15:04, 10.04it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3999/12079 [09:17<26:40:18, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4999/12079 [11:29<12:23:45,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 5999/12079 [13:23<10:35:38,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6999/12079 [15:06<8:58:54,  6.37s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 8000/12079 [16:50<5:39:29,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 9000/12079 [18:26<3:44:46,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9999/12079 [19:58<7:33:58, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10995/12079 [20:33<00:49, 22.10it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 11999/12079 [22:22<08:05,  6.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12079/12079 [22:24<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 19min 22s, sys: 35min 24s, total: 1h 54min 47s\n",
      "Wall time: 42min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "simMatrices = {}   ## store a few different similarity matrices using different scoring system, for different prediction type\n",
    "TRIM_CYCLES = 1000   ## trim full sim matrix every XX batches. \n",
    "MODES_TO_TRAIN = [\"iuf\", \"time_decay\"]\n",
    "\n",
    "for mode in MODES_TO_TRAIN:\n",
    "    ## the nested dict to store full sim matrix, {itemX: {itemY: score, itemZ: score, ...}}\n",
    "    fullSimMatrix = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "    max_idx = len(df)\n",
    "    batch_idx = 1  ## compute sim matrix for PARALLEL # of rows per batch, have a total of max_idx/PARALLEL batches.\n",
    "    for idx in tqdm(range(0, max_idx, PARALLEL)):\n",
    "        rows = df.iloc[idx: min(idx + PARALLEL, max_idx)][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "        getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, ACTION_WEIGHTS, item_total_likes, mode=mode)\n",
    "        batch_idx += 1\n",
    "        if batch_idx % TRIM_CYCLES == 0:\n",
    "            print(\"batch_idx: \", batch_idx)\n",
    "            trim_simMatrix_topk(fullSimMatrix, 100)\n",
    "            gc.collect()\n",
    "            #break\n",
    "\n",
    "    \n",
    "    ## trim top 50 when the training is complete\n",
    "    trim_simMatrix_topk(fullSimMatrix, 80)   ## TODO: make this num small enough to reduce time for normalization\n",
    "    ## max norm of each score\n",
    "    maxNormSimMatrix(fullSimMatrix)\n",
    "    \n",
    "    simMatrices[mode] = fullSimMatrix\n",
    "    \n",
    "    del fullSimMatrix\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictType[int64,float64]<iv=None>({331941: 1.0, 243711: 0.7190634944882741, 1801351: 0.5040513231086448, 371417: 0.4167012125283079, 32249: 0.41373445935315617, 899438: 0.3626232356223332, 303302: 0.3081623040015135, 461689: 0.24140817919093385, 1799312: 0.20439432086051285, 576535: 0.20363825079722686, 516937: 0.17150816792050863, 1500897: 0.1474968554333243, 807502: 0.12350333543572184, 528847: 0.12185781543011626, 734463: 0.12045400414403375, 460942: 0.1139099425003342, 12725: 0.10691090671837272, 215107: 0.09943509171737062, 893213: 0.09210204073235082, 1364441: 0.0843909572280193, 1620477: 0.07891101754442596, 355088: 0.0760826198068775, 1630327: 0.07572153181228192, 804782: 0.07362283905259837, 760663: 0.07337831080008321, 1390627: 0.07327155250282527, 1775482: 0.07042982880108292, 293222: 0.06833266345318563, 307484: 0.06657964815873083, 1432934: 0.06421905471330858, 1190046: 0.06345478375755678, 1371202: 0.0631481939274279, 1350724: 0.06124414306732429, 800979: 0.05847478548902716, 1693043: 0.05519540528206179, 932220: 0.0548184226341905, 16246: 0.05382331288999998, 808248: 0.0468322918606895, 598127: 0.046760823146036384, 103072: 0.046309211766148904, 396565: 0.046030035777334305, 1110941: 0.04092365838339326, 1099100: 0.03619644771308173, 510211: 0.03541343993983789, 639347: 0.03419103352166187, 1334074: 0.033085987748001644, 779066: 0.032644138642937116, 551290: 0.03158274416788717, 1349093: 0.03030716586650167, 652554: 0.030212446221542864, 527845: 0.028594449517798545, 1436167: 0.02846870027639107, 448706: 0.028061612990489603, 1060697: 0.027324443769941212, 723528: 0.02612315374262451, 1068049: 0.025968607215378716, 102536: 0.024083005848090942, 943586: 0.02206653719173201, 493315: 0.02119197004660886, 269602: 0.02037388714337668, 596425: 0.01930637182036119, 1635429: 0.018677605376125284, 202224: 0.01754375408122563, 1542438: 0.017252435250822866, 231588: 0.01714137028013897, 1458399: 0.016804031958741056, 22721: 0.016564447257208324, 447175: 0.016118699527914587, 307896: 0.015592268392619143, 810071: 0.015403622390389955, 851412: 0.014540034870713103, 1794652: 0.014092601761241007, 748986: 0.013794412765118282, 1511175: 0.013735502252892239, 968570: 0.013560333072959863, 292471: 0.011918520614207184, 317435: 0.011816882064306762, 77442: 0.011655700039315542, 15594: 0.01128355401653921, 37942: 0.011175260405487176})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A sanity check\n",
    "simMatrices[\"iuf\"][1517085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814440"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(simMatrices[\"iuf\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11016"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference -- Make prediction using the matrices derived from above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section D: Utils for inference:\n",
    "1. Select top items to recommend in re-ranking\n",
    "2. Compute Real time importance of each action (Not in use currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def heap_topk_return_list(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure, return a list with top \"cap\" elements with highest score\n",
    "    \"\"\"\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q)[1] for _ in range(len(q))][::-1]\n",
    "    \n",
    "    return res\n",
    "\n",
    "# ===================================\n",
    "\n",
    "# ===================================\n",
    "\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def getRealTimeActionWeight(ts_action, ts_start, ts_end, op, seq, length, ACTION_WEIGHTS, TRAIN_START_TS, TEST_END_TS):\n",
    "    \"\"\"\n",
    "    This function returns the real time importance weight of test set session actions\n",
    "    input: \n",
    "        ts_action: ts of the action takes place\n",
    "        ts_start: start_ts of this session\n",
    "        ts_end: end_ts of this session\n",
    "        op: type of the action\n",
    "        seq: seq order this action\n",
    "        length: total # of actions of this session. \n",
    "    \"\"\"\n",
    "#     overall_time_span = TEST_END_TS - TRAIN_START_TS\n",
    "#     #session_time_span = ts_end - ts_start\n",
    "#     time_to_end_of_session = ts_end - ts_action\n",
    "#     if time_to_end_of_session > 24 * 60 * 60:\n",
    "#         time_weight = 0.3\n",
    "#     else:\n",
    "#         time_weight = max(2**(1 - time_to_end_of_session/3600) - 1, 0.4)\n",
    "    ## TODO: add time decay \n",
    "    action_weight = ACTION_WEIGHTS[op]\n",
    "    sequence_weight = max(2 ** (seq/length) - 1, 0.5) ## floor at 0.1  #np.power(2, np.linspace(seq_weight_const, 1, length))[::-1] - 1\n",
    "    res = action_weight * sequence_weight # * time_weight\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section E: Main Logic in Making Inferences\n",
    "1. clicks_inferences: time_decay sim matrix + regular action weights <1, 6, 3>.\n",
    "2. carts_inferencs: iuf sim matrix + weights <4, 2, 5> (as clicks actions tend to lead to cart action next).\n",
    "3. orders_inferences: iuf sim matrix + regular action weights <1, 6, 3>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    ending_idx = starting_idx + length\n",
    "    \n",
    "    candidates = aids[starting_idx: ending_idx][::-1]\n",
    "    candidates_ops = ops[starting_idx: ending_idx][::-1]\n",
    "    \n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "\n",
    "    ## get unique aid of each session \n",
    "    unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    for a in candidates:\n",
    "        unique_aids[a] = 0\n",
    "    \n",
    "    if len(unique_aids) >= 20:   ## if the user has many actions, recommend based on the itemes it had been interacted with only.\n",
    "        PREV_INTERACT_BONUS = 10\n",
    "        sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates)))[::-1] - 1\n",
    "        for aid, op, w in zip(candidates, candidates_ops, sequence_weight):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            potential_to_recommend[aid] += w * test_ops_weights[op] * PREV_INTERACT_BONUS \n",
    "        #result[session] = np.array(heap_topk_return_list(potential_to_recommend, 20)) \n",
    "    else:  \n",
    "        for idx in range(starting_idx, ending_idx):\n",
    "            candidate = aids[idx]\n",
    "            if candidate not in potential_to_recommend:\n",
    "                potential_to_recommend[candidate] = np.inf ## ensure large weights on items had interacted with. \n",
    "    \n",
    "    ## In case some items are duplicates, when potential_to_recommend not yet reach 20, impute with items from sim matrix\n",
    "    if len(potential_to_recommend) < 80: ## CAUTIOUS: validation purpose only \n",
    "        sequence_weight = np.power(2, np.linspace(0.1, 1, len(candidates))) - 1   ## CHANGE_MADE: 0.3 -> 0.1\n",
    "        for idx in range(starting_idx, ending_idx):\n",
    "            candidate = aids[idx] \n",
    "            time_weight = 1 + 0.1 ** ((1662328791-ts[idx])/(1662328791-1659304800))    ## TODO: consider \n",
    "            candidate_realtime_weight = test_ops_weights[ops[idx]] * sequence_weight[idx-starting_idx] * time_weight  \n",
    "            ## load the potential items to recommend,\n",
    "            if candidate not in full_sim_matrix: \n",
    "                continue\n",
    "            for similar_item in full_sim_matrix[candidate]:\n",
    "#                 if similar_item in candidates:    ## skip the item if the it's already been interacted\n",
    "#                     continue\n",
    "                if similar_item not in potential_to_recommend:\n",
    "                    potential_to_recommend[similar_item] = 0\n",
    "                potential_to_recommend[similar_item] += full_sim_matrix[candidate][similar_item] * candidate_realtime_weight \n",
    "    \n",
    "    result[session] = np.array(heap_topk_return_list(potential_to_recommend, 80))   ## CAUTIOUS: validation purpose only\n",
    "    \n",
    "@nb.jit(nopython=True)\n",
    "def run_inference_parallel(rows, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1742/1742 [07:28<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 28s, sys: 37.6 s, total: 7min 5s\n",
      "Wall time: 7min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_iuf = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "result_iuf_2 = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "result_time_decay = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "    start_row = row_idx\n",
    "    end_row = min(row_idx + PARALLEL, len(df))\n",
    "    rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "    run_inference_parallel(rows, aids, ops, ts, result_iuf, simMatrices[\"iuf\"], ACTION_WEIGHTS)\n",
    "    run_inference_parallel(rows, aids, ops, ts, result_iuf_2, simMatrices[\"iuf\"], np.array([4.0, 2.0, 5.0]))   ## considebly add the weights for click action in the real time.\n",
    "    run_inference_parallel(rows, aids, ops, ts, result_time_decay, simMatrices[\"time_decay\"], ACTION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11830, 1732105,  588923,  571762,  884502,  876129, 1157882,\n",
       "       1182614,  307904, 1790438,  231487, 1517680, 1633746,   77440,\n",
       "       1586171,  855613,  735729,  205357,  756588,  523174,  258814,\n",
       "        636101,  322370, 1689044,  532616, 1317291, 1718231, 1609734,\n",
       "        409620, 1125638,  603583,  215561, 1052212, 1394029,  822934,\n",
       "       1853703, 1383529, 1425172,  135833,  500334, 1519088,   19468,\n",
       "       1349230, 1390152,  542780, 1667019,  490677,  448755, 1169267,\n",
       "       1428162, 1695994,   42241,  804966, 1677053, 1311701,  672942,\n",
       "        487136, 1197172,   45494,  697336, 1572401,  432989, 1446918,\n",
       "        577040,  696526, 1241036, 1123537, 1307712, 1041771,  600258,\n",
       "       1307461,  293000,  460148, 1032776,   87442,  198496,  972466,\n",
       "       1421968, 1097576,  823991])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_time_decay[11098528]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49529"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 32s, sys: 14.7 s, total: 5min 47s\n",
      "Wall time: 5min 56s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528_clicks</td>\n",
       "      <td>11830 1732105 588923 571762 884502 876129 1157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029 1632356 1049489 612829 295362 333991 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530_clicks</td>\n",
       "      <td>409236 264500 1603001 583026 963957 254154 752...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531_clicks</td>\n",
       "      <td>1728212 1557766 1553691 1449555 1365569 130963...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532_clicks</td>\n",
       "      <td>876469 7651 1202618 1159379 77906 476681 17040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351206</th>\n",
       "      <td>12899774_orders</td>\n",
       "      <td>33035 1539309 819288 771913 31490 95488 218795...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351207</th>\n",
       "      <td>12899775_orders</td>\n",
       "      <td>1743151 1760714 1163166 1255910 1498443 783827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351208</th>\n",
       "      <td>12899776_orders</td>\n",
       "      <td>548599 695829 1737908 773354 1762353 1440959 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351209</th>\n",
       "      <td>12899777_orders</td>\n",
       "      <td>384045 1308634 1688215 395762 703474 1486067 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351210</th>\n",
       "      <td>12899778_orders</td>\n",
       "      <td>561560 1167224 32070 971566 1175618 1314651 39...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5351211 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_type                                             labels\n",
       "0        11098528_clicks  11830 1732105 588923 571762 884502 876129 1157...\n",
       "1        11098529_clicks  1105029 1632356 1049489 612829 295362 333991 1...\n",
       "2        11098530_clicks  409236 264500 1603001 583026 963957 254154 752...\n",
       "3        11098531_clicks  1728212 1557766 1553691 1449555 1365569 130963...\n",
       "4        11098532_clicks  876469 7651 1202618 1159379 77906 476681 17040...\n",
       "...                  ...                                                ...\n",
       "5351206  12899774_orders  33035 1539309 819288 771913 31490 95488 218795...\n",
       "5351207  12899775_orders  1743151 1760714 1163166 1255910 1498443 783827...\n",
       "5351208  12899776_orders  548599 695829 1737908 773354 1762353 1440959 9...\n",
       "5351209  12899777_orders  384045 1308634 1688215 395762 703474 1486067 2...\n",
       "5351210  12899778_orders  561560 1167224 32070 971566 1175618 1314651 39...\n",
       "\n",
       "[5351211 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "subs = []\n",
    "op_names = [\"clicks\", \"carts\", \"orders\"]\n",
    "\n",
    "for result, op in zip([result_time_decay, result_iuf_2, result_iuf], op_names):\n",
    "    sub = pd.DataFrame({\"session_type\": result.keys(), \"labels\": result.values()})\n",
    "    sub.session_type = sub.session_type.astype(str) + f\"_{op}\"\n",
    "    sub.labels = sub.labels.apply(lambda x: \" \".join(x.astype(str)))\n",
    "    subs.append(sub)\n",
    "    \n",
    "submission = pd.concat(subs).reset_index(drop=True)\n",
    "#sub.sort_values(by=[\"session_type\"])  ## optional\n",
    "#submission.to_csv('submission.csv', index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.3 s, sys: 2.62 s, total: 48.9 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "submission.to_csv('../../allData/validationData/phaseII_80_items_preranking.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission.iloc[0][\"labels\"].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1783737"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff58dbd0ec383761c792d0b6d4f0a9690d9c9b1bec648659fb440990235d5b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
