{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refactor the baseline itemCF_numba, and add feature store function to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.74 s, sys: 3.06 s, total: 9.8 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv(\"../../allData/validationData/train_meta_data.csv\")\n",
    "df_test = pd.read_csv(\"../../allData/validationData/test_meta_data.csv\")\n",
    "df = pd.concat([df, df_test]).reset_index(drop = True)\n",
    "npz = np.load(\"../../allData/validationData/train_core_data.npz\")\n",
    "npz_test = np.load(\"../../allData/validationData/test_core_data.npz\")\n",
    "aids = np.concatenate([npz['aids'], npz_test['aids']])\n",
    "ts = np.concatenate([npz['ts'], npz_test['ts']])\n",
    "ops = np.concatenate([npz['ops'], npz_test['ops']])\n",
    "\n",
    "df[\"start_idx\"] = df['total_action'].cumsum().shift(1).fillna(0).astype(int)\n",
    "df[\"end_time\"] = ts[df[\"start_idx\"] + df[\"total_action\"] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>total_action</th>\n",
       "      <th>session_start_time</th>\n",
       "      <th>session_end_time</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661103727</td>\n",
       "      <td>0</td>\n",
       "      <td>1661103727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660857067</td>\n",
       "      <td>147</td>\n",
       "      <td>1660857067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1660577379</td>\n",
       "      <td>174</td>\n",
       "      <td>1660577379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1661109666</td>\n",
       "      <td>187</td>\n",
       "      <td>1661109666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1659304800</td>\n",
       "      <td>1659304900</td>\n",
       "      <td>413</td>\n",
       "      <td>1659304900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  total_action  session_start_time  session_end_time  start_idx  \\\n",
       "0        0           147          1659304800        1661103727          0   \n",
       "1        1            27          1659304800        1660857067        147   \n",
       "2        2            13          1659304800        1660577379        174   \n",
       "3        3           226          1659304800        1661109666        187   \n",
       "4        4             3          1659304800        1659304900        413   \n",
       "\n",
       "     end_time  \n",
       "0  1661103727  \n",
       "1  1660857067  \n",
       "2  1660577379  \n",
       "3  1661109666  \n",
       "4  1659304900  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training -- Derive ItemCF similarity Matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define constants\n",
    "PARALLEL = 1024\n",
    "LOOKBACK_WINDOW = 200   ## only fit the latest LOOKBACK_WINDOW to train the sim matrix\n",
    "#TOPN = 20\n",
    "ACTION_WEIGHTS = np.array([1.0, 6.0, 3.0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section A: Utils Functions \n",
    "1. Count Item Total likes: The similary score will be normalized by \"Item Total Like Scores\". In theory, popular items should have less weight in simiarity score.\n",
    "2. Trimming function: Helpful managing memoery usage. \n",
    "3. Method for normalization: Mostly item total like normalization, and max norm(make all sim score between 0 and 1) of the score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Methods for counting Item Total Likes\n",
    "# ==================================\n",
    "@nb.jit(nopython=True)\n",
    "def getItemTotalLikesNaive(aids, ops, item_total_likes, action_weights):\n",
    "    \"\"\"\n",
    "    Stores the total like score of itemXXX in item_total_likes, based on action_weights parameter. np.array([X, Y, Z])\n",
    "    \"\"\"\n",
    "    for idx, item in enumerate(aids):\n",
    "        if item not in item_total_likes: \n",
    "            item_total_likes[item] = 0\n",
    "        item_total_likes[item] += action_weights[ops[idx]]   ## TODO: For time decay, consider replace with 1, for iuf keep this. \n",
    "\n",
    "# ==================================\n",
    "# Methods for rank and trim the sim score dict\n",
    "# ==================================\n",
    "@nb.jit(nopython = True)\n",
    "def heap_topk(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure\n",
    "    \"\"\"\n",
    "    dic = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q) for _ in range(len(q))][::-1]\n",
    "    for i in range(len(res)):\n",
    "        dic[res[i][1]] = res[i][0]\n",
    "    \n",
    "    return dic\n",
    "   \n",
    "@nb.jit(nopython = True)\n",
    "def trim_simMatrix_topk(fullSimMatrix, k = 50):\n",
    "    \"\"\"\n",
    "    trim top k items of each \"itemX: {itemY: score1, ...}\" pair in fullSimMatrix based on sim scores. \n",
    "    \"\"\"\n",
    "    for item, item_cnt_dict in fullSimMatrix.items():\n",
    "        fullSimMatrix[item] = heap_topk(item_cnt_dict, k)\n",
    "\n",
    "# ==================================\n",
    "# Methods for score normalization\n",
    "# ==================================\n",
    "\n",
    "# @nb.jit(nopython=True)\n",
    "# def itemTotalLikeNorm(fullSimMatrix, item_total_likes):\n",
    "#     for aid_1, relations in fullSimMatrix.items():\n",
    "#         for aid_2, sim_score in relations.items():\n",
    "#             fullSimMatrix[aid_1][aid_2] = sim_score / (item_total_likes[aid_1] * item_total_likes[aid_2]) ** 0.1  ## TODO: consider 0.1 or other small number\n",
    "            \n",
    "@nb.jit(nopython=True)\n",
    "def maxNormSimMatrix(fullSimMatrix):\n",
    "    for aid_1, relations in fullSimMatrix.items():\n",
    "        max_num = -np.inf\n",
    "        for _, sim_score in relations.items():\n",
    "            if sim_score > max_num:\n",
    "                max_num = sim_score\n",
    "        ## DEGUG use, delete later\n",
    "        if max_num == 0:\n",
    "            print(aid_1)\n",
    "            print(fullSimMatrix[aid_1])\n",
    "        for aid_2, sim_score in relations.items():\n",
    "#             if max_num == 0:\n",
    "#                 max_num += 0.001\n",
    "            fullSimMatrix[aid_1][aid_2] = sim_score / max_num"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section B: Sim Score Computation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@nb.jit(nopython=True)\n",
    "def getSimScoresSingleRow(pairs_this_row, start_time, start_idx, length, aids, ts, ops, item_total_likes, action_weights, mode):\n",
    "    \"\"\"\n",
    "    Get the sim scores of items within single session, can be ran in parallel within each batch. \n",
    "    \"\"\"\n",
    "    max_idx = start_idx + length\n",
    "    min_idx = max(max_idx - LOOKBACK_WINDOW, start_idx)  \n",
    "    for i in range(min_idx, max_idx):\n",
    "        for j in range(i+1, max_idx):\n",
    "            if ts[j] - ts[i] > 2 * 60 * 60: continue  #TODO: try 2h only\n",
    "            if aids[i] == aids[j]: continue\n",
    "            \n",
    "            if mode == \"cosine\":\n",
    "                w_ij = action_weights[ops[j]] \n",
    "                w_ji = action_weights[ops[i]] \n",
    "            elif mode == \"iuf\":  ## penalize users that had lots of actions TODO: consider location weight\n",
    "                \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))  \n",
    "                w_ij = action_weights[ops[j]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "                w_ji = action_weights[ops[i]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "            elif mode == \"time_decay\":\n",
    "                ## calculate some time weights of each item, more weights are given when ts is later. #TODO: try adding (i-j) location weight, exponential weight, 0.5 ** (abs(i-j + 1)), \n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                #time_i = 1 + 0.1 ** ((1662328791-ts[i])/(1662328791-1659304800)) #1 + 3 * (ts[i] + start_time - 1659304800) / (1662328791 - 1659304800) #  #(1 - 0.8 *(TEST_END_TS - ts[i]) / TIME_SPAN) ** 0.5 # 0.2~1 #   ## time decay weight for item i \n",
    "                #time_j = 1 + 0.1 ** ((1662328791-ts[j])/(1662328791-1659304800))  # 1 + 3 * (ts[j] + start_time - 1659304800) / (1662328791 - 1659304800) # #  #(1 - 0.8 *(TEST_END_TS - ts[j]) / TIME_SPAN) ** 0.5   # \n",
    "                time_i = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[i])/(1662328791-1659304800)) - 0.6  )))\n",
    "                time_j = 1 + 1/(1 + math.exp(10*( ((1662328791-ts[j])/(1662328791-1659304800)) - 0.6  )))\n",
    "                \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))  \n",
    "                \n",
    "                w_ij = action_weights[ops[j]] * loc_weight * time_gap_weight * time_i / math.log1p(length)\n",
    "                w_ji = action_weights[ops[i]] * loc_weight * time_gap_weight * time_j / math.log1p(length)\n",
    "            elif mode == \"buy2buy\":\n",
    "                if (ops[i] == 0) or (ops[j] == 0):\n",
    "                    continue\n",
    "                loc_weight = 0.5**(abs(i-j))   #math.exp(-0.02 * abs(i-j)) \n",
    "                time_gap_weight = 0.5 ** (abs(ts[i]-ts[j]) / (1.5*60*60))  \n",
    "                w_ij = action_weights[ops[j]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "                w_ji = action_weights[ops[i]] * time_gap_weight * loc_weight / math.log1p(length)\n",
    "                \n",
    "            pairs_this_row[(aids[i], aids[j])] = w_ij / (item_total_likes[aids[i]] * item_total_likes[aids[j]]) ** 0.1\n",
    "            pairs_this_row[(aids[j], aids[i])] = w_ji / (item_total_likes[aids[i]] * item_total_likes[aids[j]]) ** 0.1\n",
    "\n",
    "@nb.jit(nopython=True, parallel=True, cache=True)\n",
    "def getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, action_weights, item_total_likes, mode=\"cosine\"):\n",
    "    nrows = len(rows)\n",
    "    pairs_this_batch = [{(0, 0): 0.0 for _ in range(0)} for _ in range(nrows)]\n",
    "    ## get the sim scores of each batch in seperate sub dict in pairs_this_batch\n",
    "    for row_i in nb.prange(nrows):  ## run each row of the batch in parallel\n",
    "        _, start_idx, length, start_time = rows[row_i]\n",
    "        getSimScoresSingleRow(pairs_this_batch[row_i], start_time, start_idx, length, aids, ts, ops, item_total_likes, action_weights, mode)\n",
    "    ## merge pairs_this_batch into the fullSimMatrix\n",
    "    for row_i in range(nrows):\n",
    "        for (aid1, aid2), score in pairs_this_batch[row_i].items():\n",
    "            if aid1 not in fullSimMatrix: \n",
    "                fullSimMatrix[aid1] = {0: 0.0 for _ in range(0)}\n",
    "            if aid2 not in fullSimMatrix[aid1]:\n",
    "                fullSimMatrix[aid1][aid2] = 0.0\n",
    "            fullSimMatrix[aid1][aid2] += score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section C: Train the similarity matrices\n",
    "1. Derive the total like score first\n",
    "2. Train 2 similarity matrices, one using iuf(Inverse User Frequence), the other using time_decay method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 766 ms, total: 19.7 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## get the Total Like matrix\n",
    "item_total_likes = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.float64)\n",
    "\n",
    "getItemTotalLikesNaive(aids, ops, item_total_likes, ACTION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 998/12079 [02:29<37:24,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1998/12079 [05:29<28:44,  5.85it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2998/12079 [08:13<17:17,  8.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3999/12079 [11:53<36:03:08, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 4999/12079 [14:41<33:35:59, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 6000/12079 [17:11<10:27:17,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 6999/12079 [19:25<12:24:40,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 7999/12079 [21:33<19:30:16, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 9000/12079 [23:42<10:43:56, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 9998/12079 [25:43<02:20, 14.86it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 10999/12079 [27:25<1:20:41,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 11999/12079 [28:54<23:24, 17.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12079/12079 [28:56<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 14s, sys: 25min 54s, total: 1h 17min 9s\n",
      "Wall time: 30min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "simMatrices = {}   ## store a few different similarity matrices using different scoring system, for different prediction type\n",
    "TRIM_CYCLES = 1000   ## trim full sim matrix every XX batches. \n",
    "MODES_TO_TRAIN = [\"time_decay\"] # \"iuf\", \"buy2buy\"] #, \n",
    "\n",
    "for mode in MODES_TO_TRAIN:\n",
    "    ## the nested dict to store full sim matrix, {itemX: {itemY: score, itemZ: score, ...}}\n",
    "    fullSimMatrix = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "    max_idx = len(df)\n",
    "    batch_idx = 1  ## compute sim matrix for PARALLEL # of rows per batch, have a total of max_idx/PARALLEL batches.\n",
    "    for idx in tqdm(range(0, max_idx, PARALLEL)):\n",
    "        rows = df.iloc[idx: min(idx + PARALLEL, max_idx)][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "        getSimScoreBatch(aids, ts, ops, rows, fullSimMatrix, ACTION_WEIGHTS, item_total_likes, mode=mode)\n",
    "        batch_idx += 1\n",
    "        if batch_idx % TRIM_CYCLES == 0:\n",
    "            print(\"batch_idx: \", batch_idx)\n",
    "            trim_simMatrix_topk(fullSimMatrix, 150)\n",
    "            gc.collect()\n",
    "            # break\n",
    "\n",
    "    \n",
    "    ## trim top 50 when the training is complete\n",
    "    trim_simMatrix_topk(fullSimMatrix, 150)   ## TODO: make this num small enough to reduce time for normalization, consider keeping 100, give more option for selection\n",
    "    ## max norm of each score\n",
    "    maxNormSimMatrix(fullSimMatrix)\n",
    "    \n",
    "    simMatrices[mode] = fullSimMatrix\n",
    "    \n",
    "    del fullSimMatrix\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictType[int64,float64]<iv=None>({331941: 1.0, 371417: 0.5888439497177552, 32249: 0.42943762435324906, 303302: 0.2151606169331991, 461689: 0.21463847720057422, 1371202: 0.18500509000648885, 1775482: 0.09952497694341997, 1765072: 0.07861434634553799, 1853268: 0.008780961279884873, 1231891: 0.003965427852916738, 989590: 0.002005855472564233, 320601: 0.0011189360665819362, 1190046: 0.0001025840881962515, 1236142: 1.6958427526431777e-06})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A sanity check\n",
    "simMatrices[\"buy2buy\"][1517085]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of iuf sim matrix 1818001\n",
      "len of iuf sim matrix 999742\n"
     ]
    }
   ],
   "source": [
    "print(\"len of iuf sim matrix\" ,len(simMatrices[\"iuf\"]))\n",
    "print(\"len of iuf sim matrix\" ,len(simMatrices[\"buy2buy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4097"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference -- Make prediction using the matrices derived from above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section D: Utils for inference:\n",
    "1. Select top items to recommend in re-ranking\n",
    "2. Compute Real time importance of each action (Not in use currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def heap_topk_return_list(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure, return a list with top \"cap\" elements with highest score\n",
    "    \"\"\"\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q)[1] for _ in range(len(q))][::-1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section E: Main Logic in Making Inferences (DO NOT RUN in this notebook)\n",
    "1. clicks_inferences: time_decay sim matrix + regular action weights <1, 6, 3>.\n",
    "2. carts_inferencs: iuf sim matrix + weights <4, 2, 5> (as clicks actions tend to lead to cart action next).\n",
    "3. orders_inferences: iuf sim matrix + regular action weights <1, 6, 3>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    PREV_INTERACT_BONUS = 10\n",
    "    NEARBY_ACTION_BONUS = 1.5\n",
    "    \n",
    "    ending_idx = starting_idx + length\n",
    "    end_time = ts[ending_idx]\n",
    "    \n",
    "    candidates = aids[starting_idx: ending_idx][::-1]\n",
    "    candidates_ops = ops[starting_idx: ending_idx][::-1]\n",
    "    \n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "    \n",
    "    ## get unique aid of each session \n",
    "    unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    for a in candidates:\n",
    "        unique_aids[a] = 0\n",
    "    \n",
    "    ## Sequence weight to all the candidates, from near to far \n",
    "    sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates)))[::-1] - 1\n",
    "    \n",
    "    ## Time weight of all candidates, from near to far\n",
    "    time_weights = []\n",
    "    for idx in range(starting_idx, ending_idx):\n",
    "        if end_time - ts[idx] < 2 * 60 * 60:   ## apply nearby action bonus\n",
    "            time_weight = (1 + 0.5 ** ((end_time - ts[idx])/(end_time - start_time))) * NEARBY_ACTION_BONUS\n",
    "        else:\n",
    "            time_weight = 1 + 0.5 ** ((end_time - ts[idx])/(end_time - start_time))\n",
    "        time_weights.append(time_weight)\n",
    "    time_weights = time_weights[::-1]\n",
    "    \n",
    "    \n",
    "    ## making inference\n",
    "    if len(unique_aids) >= 20:  \n",
    "        for aid, op, seq_w, time_w in zip(candidates, candidates_ops, sequence_weight, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            potential_to_recommend[aid] += seq_w * time_w * test_ops_weights[op] #* PREV_INTERACT_BONUS\n",
    "    else:   ## otherwise, fill the rest with similar items.\n",
    "        for aid, op, seq_w, time_w in zip(candidates, candidates_ops, sequence_weight, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            potential_to_recommend[aid] += np.inf #seq_w * time_w * test_ops_weights[op] * PREV_INTERACT_BONUS\n",
    "            ## adding the similar items, if full_sim_matrix don't have such record, skip. \n",
    "            if aid not in full_sim_matrix:\n",
    "                continue\n",
    "            for similar_item in full_sim_matrix[aid]:\n",
    "                ## if sim_item is in candidates, would be included above anyways, skip \n",
    "                if similar_item in candidates:\n",
    "                    continue\n",
    "                if similar_item not in potential_to_recommend:\n",
    "                    potential_to_recommend[similar_item] = 0\n",
    "                potential_to_recommend[similar_item] += seq_w * time_w * test_ops_weights[op] * full_sim_matrix[aid][similar_item]  ## no PREV_INTERACT_BONUS as expected, replaced with sim_matrix scores\n",
    "    result[session] = np.array(heap_topk_return_list(potential_to_recommend, 20))\n",
    "    \n",
    "@nb.jit(nopython=True)\n",
    "def run_inference_parallel(rows, aids, ops, ts, result, full_sim_matrix, test_ops_weights):\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        inference_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, test_ops_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# result_iuf = nb.typed.Dict.empty(\n",
    "#     key_type = nb.types.int64,\n",
    "#     value_type = nb.types.int64[:])\n",
    "\n",
    "# result_iuf_2 = nb.typed.Dict.empty(\n",
    "#     key_type = nb.types.int64,\n",
    "#     value_type = nb.types.int64[:])\n",
    "\n",
    "# result_time_decay = nb.typed.Dict.empty(\n",
    "#     key_type = nb.types.int64,\n",
    "#     value_type = nb.types.int64[:])\n",
    "\n",
    "# for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "#     start_row = row_idx\n",
    "#     end_row = min(row_idx + PARALLEL, len(df))\n",
    "#     rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "#     run_inference_parallel(rows, aids, ops, ts, result_iuf, simMatrices[\"iuf\"], np.array([2.0, 6.0, 6.0]))\n",
    "#     run_inference_parallel(rows, aids, ops, ts, result_iuf_2, simMatrices[\"iuf\"], np.array([4.0, 2.0, 5.0]))   ## considebly add the weights for click action in the real time.\n",
    "#     run_inference_parallel(rows, aids, ops, ts, result_time_decay, simMatrices[\"time_decay\"], np.array([3.0, 6.0, 3.0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submissions - Convert results to csv, get validation set result - DO NOT RUN in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# subs = []\n",
    "# op_names = [\"clicks\", \"carts\", \"orders\"]\n",
    "\n",
    "# for result, op in zip([result_time_decay, result_iuf_2, result_iuf], op_names):\n",
    "#     sub = pd.DataFrame({\"session_type\": result.keys(), \"labels\": result.values()})\n",
    "#     sub.session_type = sub.session_type.astype(str) + f\"_{op}\"\n",
    "#     sub.labels = sub.labels.apply(lambda x: \" \".join(x.astype(str)))\n",
    "#     subs.append(sub)\n",
    "    \n",
    "# submission = pd.concat(subs).reset_index(drop=True)\n",
    "# #sub.sort_values(by=[\"session_type\"])  ## optional\n",
    "# #submission.to_csv('submission.csv', index = False)\n",
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# submission.to_csv('../../allData/validationData/p_v_579_80_items.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section F: Saving Feature, Run E or F, depends on mode, this will not only generate result, but the featues associated.\n",
    "**Feature engineering are made here**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def getLocalTsInfo(utc_ts, timezone):\n",
    "    local_times_info = datetime.fromtimestamp(utc_ts, pytz.timezone(timezone))\n",
    "    if (local_times_info.hour >= 18) or (local_times_info.hour <= 2):\n",
    "        day_noon_night = 2\n",
    "    elif (local_times_info.hour >= 3) and (local_times_info.hour <= 11):\n",
    "        day_noon_night = 1\n",
    "    else: ## (local_times_info.hour >= 12) and (local_times_info.hour <= 15)\n",
    "        day_noon_night = 0\n",
    "    return local_times_info.day, local_times_info.hour, day_noon_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA (1, 8, 1)\n",
      "Berlin: (1, 17, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"LA\", getLocalTsInfo(1659367439, 'America/Los_Angeles'))\n",
    "print(\"Berlin:\", getLocalTsInfo(1659367439, 'Europe/Berlin'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utils for features save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def update_feature_vec(aid, features_tuple_arr, features_idx_map, new_feat_tuple):\n",
    "    ## append features\n",
    "    if aid not in features_idx_map:\n",
    "        features_tuple_arr.append(new_feat_tuple)\n",
    "        new_pos = len(features_tuple_arr)-1\n",
    "        ## save the position in the tuple arr\n",
    "        features_idx_map[aid] = new_pos\n",
    "    else: # <is_prev_int, seq_w, time_w, total_ops_w, session_len, # uniuqe aids, CF_score, aid's itemTotalLike >\n",
    "        # ================== 8 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot8_ref_time = features_tuple_arr[features_idx_map[aid]][8]\n",
    "        else:\n",
    "            slot8_ref_time = features_tuple_arr[features_idx_map[aid]][8] + new_feat_tuple[8]\n",
    "        # ================== 9 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot9_max_sim = 1\n",
    "        else:\n",
    "            slot9_max_sim = max(new_feat_tuple[9], features_tuple_arr[features_idx_map[aid]][9])\n",
    "        # ================== 10 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot10_mean_sim = 1\n",
    "        else:\n",
    "            slot10_mean_sim = ((features_tuple_arr[features_idx_map[aid]][10] * (features_tuple_arr[features_idx_map[aid]][8]-1) ) + new_feat_tuple[10] ) / features_tuple_arr[features_idx_map[aid]][8]\n",
    "        # ================== 14 seq_w ==\n",
    "        slot14_max_seq_w = max(new_feat_tuple[14], features_tuple_arr[features_idx_map[aid]][14])\n",
    "        # ================== 15 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot15_mean_seq_w = (features_tuple_arr[features_idx_map[aid]][1] + new_feat_tuple[1]) / (features_tuple_arr[features_idx_map[aid]][11] + new_feat_tuple[11])\n",
    "        else:\n",
    "            slot15_mean_seq_w = (features_tuple_arr[features_idx_map[aid]][1] + new_feat_tuple[1]) / (features_tuple_arr[features_idx_map[aid]][8] + new_feat_tuple[8])\n",
    "        # ================== 16 ==\n",
    "        slot16_min_seq_w = min(new_feat_tuple[16], features_tuple_arr[features_idx_map[aid]][16])\n",
    "        # ================== 17 time_w == \n",
    "        slot17_max_time_w = max(new_feat_tuple[17], features_tuple_arr[features_idx_map[aid]][17])\n",
    "        # ================== 18 == \n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot18_mean_time_w = (features_tuple_arr[features_idx_map[aid]][2] + new_feat_tuple[2]) / (features_tuple_arr[features_idx_map[aid]][11] + new_feat_tuple[11])\n",
    "        else:\n",
    "            slot18_mean_time_w = (features_tuple_arr[features_idx_map[aid]][2] + new_feat_tuple[2]) / (features_tuple_arr[features_idx_map[aid]][8] + new_feat_tuple[8])\n",
    "        # ================= 19 ==\n",
    "        slot19_min_time_w = min(new_feat_tuple[19], features_tuple_arr[features_idx_map[aid]][19])\n",
    "        # ================= 20 ops_w ==\n",
    "        slot20_max_ops_w = max(new_feat_tuple[20], features_tuple_arr[features_idx_map[aid]][20])\n",
    "        # ================= 21 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot21_mean_ops_w = (features_tuple_arr[features_idx_map[aid]][3] + new_feat_tuple[3]) / (features_tuple_arr[features_idx_map[aid]][11] + new_feat_tuple[11])\n",
    "        else:\n",
    "            slot21_mean_ops_w = (features_tuple_arr[features_idx_map[aid]][3] + new_feat_tuple[3]) / (features_tuple_arr[features_idx_map[aid]][8] + new_feat_tuple[8])\n",
    "        # ================= 22 ==\n",
    "        slot22_min_ops_w = min(new_feat_tuple[22], features_tuple_arr[features_idx_map[aid]][22]) #new_feat_tuple[22] if new_feat_tuple[22] < features_tuple_arr[features_idx_map[aid]][22] else features_tuple_arr[features_idx_map[aid]][22]\n",
    "        # ================= 28 cf_incre ==\n",
    "        slot28_max_cf_incre = max(new_feat_tuple[28], features_tuple_arr[features_idx_map[aid]][28])\n",
    "        # ================= 29 ==\n",
    "        if features_tuple_arr[features_idx_map[aid]][0]: \n",
    "            slot29_mean_cf_incre = new_feat_tuple[6] / (features_tuple_arr[features_idx_map[aid]][11] + new_feat_tuple[11])\n",
    "        else:\n",
    "            slot29_mean_cf_incre = new_feat_tuple[6] / (features_tuple_arr[features_idx_map[aid]][8] + new_feat_tuple[8])\n",
    "        # ================= 30 ==\n",
    "        slot30_min_cf_incre = min(new_feat_tuple[30], features_tuple_arr[features_idx_map[aid]][30])\n",
    "\n",
    "        \n",
    "        features_tuple_arr[features_idx_map[aid]] = (new_feat_tuple[0], \n",
    "                                                     features_tuple_arr[features_idx_map[aid]][1] + new_feat_tuple[1], \n",
    "                                                     features_tuple_arr[features_idx_map[aid]][2] + new_feat_tuple[2], \n",
    "                                                     features_tuple_arr[features_idx_map[aid]][3] + new_feat_tuple[3],\n",
    "                                                     new_feat_tuple[4],\n",
    "                                                     new_feat_tuple[5],\n",
    "                                                     new_feat_tuple[6],\n",
    "                                                     new_feat_tuple[7],\n",
    "                                                     slot8_ref_time,\n",
    "                                                     slot9_max_sim,\n",
    "                                                     slot10_mean_sim,\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][11] + new_feat_tuple[11],\n",
    "                                                     new_feat_tuple[12],\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][13],   ## should stay as the 1st iter\n",
    "                                                     slot14_max_seq_w,\n",
    "                                                     slot15_mean_seq_w,\n",
    "                                                     slot16_min_seq_w,\n",
    "                                                     slot17_max_time_w,\n",
    "                                                     slot18_mean_time_w,\n",
    "                                                     slot19_min_time_w,\n",
    "                                                     slot20_max_ops_w,\n",
    "                                                     slot21_mean_ops_w,\n",
    "                                                     slot22_min_ops_w,\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][23] + new_feat_tuple[23], \n",
    "                                                     features_tuple_arr[features_idx_map[aid]][24] + new_feat_tuple[24],\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][25] + new_feat_tuple[25],\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][26], ## should not change once set at the 1st iter\n",
    "                                                     features_tuple_arr[features_idx_map[aid]][27], ## should stay as the 1st iter\n",
    "                                                     slot28_max_cf_incre,\n",
    "                                                     slot29_mean_cf_incre,\n",
    "                                                     slot30_min_cf_incre,\n",
    "                                                     slot14_max_seq_w - slot16_min_seq_w,\n",
    "                                                     slot17_max_time_w - slot19_min_time_w,\n",
    "                                                     slot20_max_ops_w - slot22_min_ops_w,\n",
    "                                                     slot28_max_cf_incre - slot30_min_cf_incre\n",
    "                                                     )\n",
    "\n",
    "# <\n",
    "# slot_0: is_prev_interacted, \n",
    "# slot_1: seq_w_total, \n",
    "# slot_2: time_w_total, \n",
    "# slot_3: ops_w_total: for visited item, ops weight total in this session; for unvisited item, ops weight total of the item referencing this item. \n",
    "# slot_4: session_len, \n",
    "# slot_5: num uniuqe aids, \n",
    "# slot_6: CF_score, \n",
    "# slot_7: aid's itemTotalLike: total like score use for normalization.  \n",
    "# slot_8: reference time by similar matrix(if aid visited, default 100; if aid not visited, 1-19(when all aid only interact once, could grow to very large if a lot of actions on one aid), depending how many aid reference this item)\n",
    "# slot_9: max_sim_score:  (1 if it's a visited item)\n",
    "# slot_10: mean_sim_score: (1 if it's a visited item)\n",
    "# slot_11: num_interact, (0 for unvisited item; count of interaction for visited item)\n",
    "# slot_12: time_span of the session \n",
    "# slot_13: action_recency: time to last action(end time), for unvisited items -> the time to of reference_aid to the last action\n",
    "# slot_14: seq_w_max: \n",
    "# slot_15: seq_w_mean: for visited item -> seq_w_total / num_interact; for unvisited item -> seq_w_total / reference_time\n",
    "## ========================= round 2 ================\n",
    "# slot_16: seq_w_min: \n",
    "# slot_17: time_w_max:\n",
    "# slot_18: time_w_mean: similar to slot_15\n",
    "# slot_19: time_w_min\n",
    "# slot_20: ops_w_max:\n",
    "# slot_21: ops_w_mean:\n",
    "# slot_22: ops_w_min: \n",
    "# slot_23: num_clicks: visited item, direct num; unvisited item, take the reference item's num\n",
    "# slot_24: num_carts:\n",
    "# slot_25: num_orders:\n",
    "# slot_26: last_action_type: 0 -> clicks, 1-> carts, 2 -> orders\n",
    "# slot_27: time_to_now: latest interaction time to now \n",
    "# slot_28: cf_increment_max: \n",
    "# slot_29: cf_increment_mean:\n",
    "# slot_30: cf_increment_min:\n",
    "##  ======================== Derivable ============================\n",
    "# slot_31: seq_w max_min_gap: slot_14 - slot_16 \n",
    "# slot_32: time_w_max_min_gap: slot_17 - slot_19\n",
    "# slot_33: ops_w_max_min_gap: slot_20 - slot_22\n",
    "# slot_34: cf_incre_max_min_gap: slot_28 - slot_30\n",
    "## ====================== Round 3 features ========================\n",
    "# slot_35: last3Inter_cf_incre_max: maximum cf_incre in the last 3 action, if <= 3 actions, same as slot_28\n",
    "# slot_36: last3Inter_cf_incre_mean: \n",
    "# slot_37: last3Inter_cf_incre_min:\n",
    "# slot_38: last3Inter_time_w_max:  maximum time_w in the last 3 action, if <= 3 actions, same as slot_17\n",
    "# slot_39: last3Inter_time_w_mean:\n",
    "# slot_40: last3Inter_time_w_min: \n",
    "# slot_41: last3Inter_seq_w_max:  maximum time_w in the last 3 action, if <= 3 actions, same as slot_14\n",
    "# slot_42: last3Inter_seq_w_mean:\n",
    "# slot_43: last3Inter_seq_w_min:\n",
    "# slot_44: raw_seq_order: last action's seq_order, no depreciation\n",
    "# slot_45: raw_seq_order_max: \n",
    "# slot_46: raw_seq_order_mean:\n",
    "# slot_47: raw_seq_order_min\n",
    "\n",
    "# append ts lastly to unblock feature below\n",
    "#  \n",
    "\n",
    "## ================= numba restriction, add in notebook =====================\n",
    "# slot_35: last_interact_local_day_of_week, Mon -> 0; Tues -> 1; ..... ; Sun -> 6\n",
    "# slot_36: last_interact_local_hour: \n",
    "# slot_37: last_interact_day_night, local ts, if 18:00:00 ~ 2:59:59 -> night/2; 3:00:00 ~ 11:59:59 -> morning/1; 12:00:00 ~ 17:59:59 -> afternoon/0\n",
    "# >\n",
    "FEATURE_TUPLE_TEMPLATE = (bool(0), np.float64(0.0), np.float64(0.0), np.int64(0), np.int64(0), np.int64(0), \\\n",
    "    np.float64(0.0), np.float64(0.0), np.int32(0), np.float32(0.0), np.float64(0.0), np.int32(0), np.float64(0.0), np.float64(0.0), np.float32(0.0), np.float32(0.0),\\\n",
    "        np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0),\\\n",
    "            np.int32(0), np.int32(0), np.int32(0), np.int32(0), np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0), \\\n",
    "                np.float32(0.0), np.float32(0.0), np.float32(0.0), np.float32(0.0))\n",
    "\n",
    "FEATURE_NAMES = [\"prev_int\", \"seq_w_total\", \"time_w_total\", \"ops_w_total\", \"session_len\", \"num_uniuqe_aids\", \"CF_score\", \"itemTotalLike\", \"ref_time\", \"max_sim_score\",\\\n",
    "    \"mean_sim_score\", \"num_interact\", \"time_span\", \"action_recency\", \"seq_w_max\", \"seq_w_mean\", \"seq_w_min\", \"time_w_max\", \"time_w_mean\", \"time_w_min\", \\\n",
    "        \"ops_w_max\", \"ops_w_mean\", \"ops_w_min\", \"num_clicks\", \"num_carts\", \"num_orders\", \"last_action_type\", \"time_to_now\", \"cf_incre_max\", \"cf_incre_mean\", \\\n",
    "            \"cf_incre_min\", \"seqW_max_min_gap\", \"timeW_max_min_gap\", \"opsW_max_min_gap\", \"cf_incre_max_min_gap\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main feature save logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def save_feature_single_session(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, item_total_likes, test_ops_weights):\n",
    "    NOW_TIME = ts[-1] ## ts of latest avaiable action\n",
    "    PREV_INTERACT_BONUS = 20\n",
    "    NEARBY_ACTION_BONUS = 1.5\n",
    "    \n",
    "    ending_idx = starting_idx + length \n",
    "    end_time = ts[ending_idx - 1]\n",
    "    time_span = end_time - start_time\n",
    "    \n",
    "    candidates = aids[starting_idx: ending_idx][::-1]\n",
    "    candidates_ops = ops[starting_idx: ending_idx][::-1]\n",
    "    \n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "    \n",
    "    ## get unique aid of each session \n",
    "    unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    for a in candidates:\n",
    "        unique_aids[a] = 0\n",
    "    \n",
    "    ## Sequence weight to all the candidates, from near to far \n",
    "    sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates)))[::-1] - 1\n",
    "    \n",
    "    ## Time weight of all candidates, from near to far\n",
    "    time_weights = []\n",
    "    time_lapse = end_time - start_time + 1  ## +1 to avoid zero\n",
    "    for idx in range(starting_idx, ending_idx):\n",
    "        if end_time - ts[idx] < 2 * 60 * 60:   ## apply nearby action bonus\n",
    "            time_weight = (1 + 0.5 ** ((end_time - ts[idx])/time_lapse)) * NEARBY_ACTION_BONUS\n",
    "        else:\n",
    "            time_weight = 1 + 0.5 ** ((end_time - ts[idx])/time_lapse)\n",
    "        time_weights.append(time_weight)\n",
    "    time_weights = time_weights[::-1]\n",
    "    \n",
    "    ## feature vector template: [aid: <is_prev_int, seq_w, time_w, associated_action, session_len,.. >]\n",
    "    features_tuple_arr = nb.typed.List()\n",
    "    features_tuple_arr.append(FEATURE_TUPLE_TEMPLATE)\n",
    "    features_idx_map = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.int64)\n",
    "\n",
    "    helper_idx = ending_idx - 1\n",
    "    ## making inference\n",
    "    if len(unique_aids) >= 20:  \n",
    "        for aid, op, seq_w, time_w in zip(candidates, candidates_ops, sequence_weight, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            ## caculate scores\n",
    "            cf_incre = seq_w * time_w * test_ops_weights[op]\n",
    "            potential_to_recommend[aid] += cf_incre #* PREV_INTERACT_BONUS\n",
    "            ## append features\n",
    "            update_feature_vec(aid, features_tuple_arr, features_idx_map, \\\n",
    "                (1, seq_w, time_w, test_ops_weights[op], length, len(unique_aids), potential_to_recommend[aid], \\\n",
    "                    item_total_likes[aid], 100, 1, 1, 1, time_span, end_time-ts[helper_idx], seq_w, seq_w, seq_w, \\\n",
    "                        time_w, time_w, time_w, test_ops_weights[op], test_ops_weights[op], test_ops_weights[op], op==0, op==1, op==2, op, NOW_TIME-ts[helper_idx],\\\n",
    "                            cf_incre, cf_incre, cf_incre, 0, 0, 0, 0))\n",
    "            helper_idx -= 1\n",
    "    else:   ## otherwise, fill the rest with similar items.\n",
    "        for aid, op, seq_w, time_w in zip(candidates, candidates_ops, sequence_weight, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "            ## get the scores\n",
    "            cf_incre = seq_w * time_w * test_ops_weights[op] * PREV_INTERACT_BONUS\n",
    "            potential_to_recommend[aid] += cf_incre\n",
    "            ## append features\n",
    "            update_feature_vec(aid, features_tuple_arr, features_idx_map, \\\n",
    "                (1, seq_w, time_w, test_ops_weights[op], length, len(unique_aids), potential_to_recommend[aid], \\\n",
    "                    item_total_likes[aid], 100, 1, 1, 1, time_span, end_time-ts[helper_idx], seq_w, seq_w, seq_w, \\\n",
    "                        time_w, time_w, time_w, test_ops_weights[op], test_ops_weights[op], test_ops_weights[op], op==0, op==1, op==2, op, NOW_TIME - ts[helper_idx],\\\n",
    "                            cf_incre, cf_incre, cf_incre, 0, 0, 0, 0))\n",
    "            ## adding the similar items, if full_sim_matrix don't have such record, skip. \n",
    "            if aid not in full_sim_matrix:\n",
    "                continue\n",
    "            for similar_item in full_sim_matrix[aid]:\n",
    "                ## if sim_item is in candidates, would be included above anyways, skip \n",
    "                if similar_item in candidates:\n",
    "                    continue\n",
    "                if similar_item not in potential_to_recommend:\n",
    "                    potential_to_recommend[similar_item] = 0\n",
    "                \n",
    "                cf_incre = seq_w * time_w * test_ops_weights[op] * full_sim_matrix[aid][similar_item]\n",
    "                potential_to_recommend[similar_item] += cf_incre  ## no PREV_INTERACT_BONUS as expected, replaced with sim_matrix scores\n",
    "                ## append features\n",
    "                update_feature_vec(similar_item, features_tuple_arr, features_idx_map, \\\n",
    "                    (0, seq_w, time_w, test_ops_weights[op], length, len(unique_aids), potential_to_recommend[similar_item], \\\n",
    "                        item_total_likes[similar_item], 1, full_sim_matrix[aid][similar_item], full_sim_matrix[aid][similar_item], 0, \\\n",
    "                            time_span, end_time-ts[helper_idx], seq_w, seq_w, seq_w, time_w, time_w, time_w, test_ops_weights[op], test_ops_weights[op], test_ops_weights[op], op==0, op==1, op==2, op,\\\n",
    "                                NOW_TIME-ts[helper_idx], cf_incre, cf_incre, cf_incre, 0, 0, 0, 0))\n",
    "            helper_idx -= 1\n",
    "\n",
    "    result[session] = np.array(heap_topk_return_list(potential_to_recommend, 60))  ## Take top 100 for validation runs. \n",
    "    \n",
    "    feature_tuples_this_session = []\n",
    "    for aid in result[session]:\n",
    "#         features_save[(session, aid)] = features_tuple_arr[features_idx_map[aid]]\n",
    "        feature_tuples_this_session.append(features_tuple_arr[features_idx_map[aid]])\n",
    "    \n",
    "    return feature_tuples_this_session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils for batch processing the features save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt_tables(type):\n",
    "    \"\"\" type -> carts / orders \"\"\"\n",
    "    gt_labels = pd.read_json(\"../../allData/validationData/out_7day_test/test_labels.jsonl\", lines=True)\n",
    "    gt_labels['aids'] = gt_labels[\"labels\"].apply(lambda x: x.get(type))\n",
    "    gt_labels = gt_labels[gt_labels.aids.notnull()]\n",
    "    gt_labels = gt_labels.drop(\"labels\", axis = 1)\n",
    "    ## ========= special df to identify the unique session id to look at ================\n",
    "    valid_gt_sessions = gt_labels.drop(\"aids\", axis = 1) \n",
    "    ## ========================================================================\n",
    "    ## keep go on for gt labels processing\n",
    "    gt_labels = gt_labels.set_index(['session']).apply(pd.Series.explode).reset_index()\n",
    "    gt_labels[\"gt\"] = 1\n",
    "    return valid_gt_sessions, gt_labels\n",
    "\n",
    "def process_batch_pipeline(rawDf, valid_gt_sessions, gt_labels):\n",
    "    \"\"\" rawDf -> Df with session, aids(100), feature_tuple \"\"\"\n",
    "    ## join valid_gt_session with rawDf, now only gt_features in valid sessions(have at least 1 aid to predict) are kept\n",
    "    gt_features_valid_session = pd.merge(rawDf, valid_gt_sessions, on=\"session\")\n",
    "\n",
    "    ## Now explode the whole valid_gt_session aids, these session - aid are served as the train/val/test data for the reranker model, \n",
    "    ## for orders, \n",
    "    ## for carts, a total of 569697 correct guesses(not 100% included in the recall)\n",
    "    gt_features_valid_session = gt_features_valid_session.set_index(['session']).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "    ## finally, attach the gt_lables 1/null to the df to return\n",
    "    final_df = pd.merge(gt_features_valid_session, gt_labels, on=[\"session\", \"aids\"], how='left')\n",
    "\n",
    "    # ## open up the feature tuple \n",
    "    # for slot_id, f_name in enumerate(FEATURE_NAMES):\n",
    "    #     final_df[f_name] = final_df[\"feature_tuple\"].apply(lambda x: x[slot_id])\n",
    "\n",
    "    # new crazy fast method\n",
    "    features = np.vstack(final_df[\"feature_tuple\"].values)\n",
    "    temp_df = pd.DataFrame(features)\n",
    "    del features\n",
    "    temp_df.columns = [f'{feat_name}' for feat_name in FEATURE_NAMES]\n",
    "    final_df[temp_df.columns] = temp_df\n",
    "    del temp_df\n",
    "    \n",
    "\n",
    "    final_df = final_df.drop(\"feature_tuple\", axis = 1)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save features as batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading the gt datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 18/1742 [00:24<1:55:08,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_0 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 35/1742 [00:46<1:39:53,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_1 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 52/1742 [01:10<1:47:59,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_2 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 69/1742 [01:33<1:43:57,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_3 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 86/1742 [01:57<1:49:50,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_4 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 103/1742 [02:18<1:36:27,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_5 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 120/1742 [02:41<1:43:11,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_6 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 137/1742 [03:03<1:35:05,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_7 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 154/1742 [03:25<1:37:05,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_8 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 171/1742 [03:47<1:41:42,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_9 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 188/1742 [04:09<1:30:26,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_10 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 205/1742 [04:30<1:28:02,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_11 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 222/1742 [04:52<1:32:09,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_12 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 239/1742 [05:13<1:27:31,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_13 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 256/1742 [05:34<1:26:32,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_14 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 273/1742 [05:56<1:32:43,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_15 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 290/1742 [06:18<1:25:56,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_16 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 307/1742 [06:39<1:24:39,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_17 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 324/1742 [07:01<1:18:46,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_18 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 341/1742 [07:20<1:13:38,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_19 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 358/1742 [07:40<1:12:31,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_20 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 375/1742 [08:00<1:13:54,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_21 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 392/1742 [08:20<1:12:39,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_22 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 409/1742 [08:40<1:14:55,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_23 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 426/1742 [09:01<1:15:11,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_24 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 443/1742 [09:21<1:10:47,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_25 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 460/1742 [09:41<1:10:30,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_26 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 477/1742 [10:02<1:09:34,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_27 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 494/1742 [10:21<1:07:29,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_28 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 511/1742 [10:41<1:06:39,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_29 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 528/1742 [11:01<1:06:52,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_30 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 545/1742 [11:20<1:04:48,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_31 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 562/1742 [11:41<1:05:22,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_32 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 579/1742 [12:01<1:03:57,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_33 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 596/1742 [12:21<1:02:52,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_34 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 613/1742 [12:41<1:01:57,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_35 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 630/1742 [13:02<1:02:31,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_36 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 647/1742 [13:22<1:02:14,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_37 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 664/1742 [13:43<1:02:09,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_38 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 681/1742 [14:04<1:00:13,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_39 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 698/1742 [14:24<57:47,  3.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_40 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 715/1742 [14:44<57:07,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_41 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 732/1742 [15:04<55:30,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_42 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 749/1742 [15:25<59:27,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_43 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 766/1742 [15:47<59:32,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_44 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 783/1742 [16:07<54:36,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_45 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 800/1742 [16:28<56:47,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_46 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 817/1742 [16:50<57:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_47 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 834/1742 [17:11<51:14,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_48 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 851/1742 [17:31<48:47,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_49 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 868/1742 [17:51<48:29,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_50 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 885/1742 [18:13<51:39,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_51 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 902/1742 [18:33<47:15,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_52 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 919/1742 [18:54<46:53,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_53 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 936/1742 [19:14<45:08,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_54 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 953/1742 [19:35<45:37,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_55 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 970/1742 [19:55<42:57,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_56 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 987/1742 [20:15<42:38,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_57 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1004/1742 [20:35<40:35,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_58 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1021/1742 [20:55<40:27,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_59 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1038/1742 [21:15<40:09,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_60 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1055/1742 [21:36<38:41,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_61 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1072/1742 [21:56<37:05,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_62 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1089/1742 [22:16<36:02,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_63 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1106/1742 [22:35<34:25,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_64 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1123/1742 [22:55<34:13,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_65 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1140/1742 [23:15<33:30,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_66 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1157/1742 [23:35<32:10,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_67 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1174/1742 [23:55<31:01,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_68 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1191/1742 [24:15<31:13,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_69 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1208/1742 [24:35<29:23,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_70 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1225/1742 [24:55<29:30,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_71 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1242/1742 [25:14<27:05,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_72 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1259/1742 [25:34<25:36,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_73 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1276/1742 [25:53<24:57,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_74 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1293/1742 [26:12<24:12,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_75 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1310/1742 [26:32<22:56,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_76 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1327/1742 [26:51<22:49,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_77 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1344/1742 [27:11<21:21,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_78 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1361/1742 [27:30<20:07,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_79 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1378/1742 [27:49<18:57,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_80 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1395/1742 [28:07<18:02,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_81 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1412/1742 [28:27<17:36,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_82 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1429/1742 [28:47<17:45,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_83 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1446/1742 [29:07<16:23,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_84 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1463/1742 [29:27<15:54,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_85 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1480/1742 [29:48<15:33,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_86 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1497/1742 [30:09<14:13,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_87 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1514/1742 [30:30<13:04,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_88 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1531/1742 [30:51<12:16,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_89 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1548/1742 [31:12<10:51,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_90 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1565/1742 [31:32<09:40,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_91 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1582/1742 [31:53<09:18,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_92 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1599/1742 [32:13<07:57,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_93 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1616/1742 [32:32<07:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_94 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1633/1742 [32:52<06:10,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_95 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1650/1742 [33:12<05:09,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_96 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1667/1742 [33:32<04:05,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_97 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1684/1742 [33:50<03:06,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_98 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1701/1742 [34:11<02:23,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_99 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1718/1742 [34:31<01:22,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_100 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1735/1742 [34:49<00:22,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_101 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1742/1742 [34:57<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_102 completes saving.\n",
      "CPU times: user 31min 59s, sys: 2min 42s, total: 34min 42s\n",
      "Wall time: 35min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_time_decay_clicks = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "features_all_sessions = [] # session, aid, feature tuple\n",
    "                          ## session, aid, feature tuple\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "## Given there are 1671803 sessions in total, we separate them into K batches\n",
    "K = 100\n",
    "session_per_batch = len(df_test) // K \n",
    "row_idx_cutoffs = [(len(df) - len(df_test)) + (PARALLEL * (session_per_batch//PARALLEL) ) * i for i in range(1, K+3)]   ## batch process every 1024 * 136 rows\n",
    "\n",
    "feature_batch_id = 0\n",
    "## load important tables\n",
    "valid_gt_sessions, gt_labels = load_gt_tables(\"clicks\")\n",
    "print(\"finish loading the gt datas\")\n",
    "\n",
    "for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "    start_row = row_idx\n",
    "    end_row = min(row_idx + PARALLEL, len(df))\n",
    "    rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "#     save_features_parallel(rows, aids, ops, ts, result_iuf_orders, simMatrices[\"iuf\"], np.array([2.0, 8.0, 6.0]), orders_features_save)  \n",
    "    ## run things in parallel\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        features_tuples_this_session = save_feature_single_session(session, starting_idx, length, start_time, aids, ops, ts, result_time_decay_clicks, simMatrices[\"time_decay\"], item_total_likes, np.array([3.0, 6.0, 3.0]))\n",
    "        features_all_sessions.append(features_tuples_this_session)\n",
    "    # break\n",
    "    \n",
    "    if (start_row in row_idx_cutoffs) or (end_row == len(df)):\n",
    "        ## save batch result\n",
    "        rawDf = pd.DataFrame({\"session\": result_time_decay_clicks.keys(), \"aids\": result_time_decay_clicks.values(), \"feature_tuple\": features_all_sessions})\n",
    "        batch_result = process_batch_pipeline(rawDf, valid_gt_sessions, gt_labels)\n",
    "        batch_result.to_parquet(f\"../../allData/features/click_features_V5/batch_result_{feature_batch_id}.parquet\")\n",
    "        ## clean the memory for next batch\n",
    "        del batch_result, rawDf, features_all_sessions, result_time_decay_clicks\n",
    "        gc.collect()\n",
    "        ## progress update\n",
    "        print(f\"feature_batch_{feature_batch_id} completes saving.\")\n",
    "        feature_batch_id += 1\n",
    "        ## initiate the struct for new batch again\n",
    "        result_time_decay_clicks = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.types.int64[:])\n",
    "        features_all_sessions = []\n",
    "        \n",
    "    #break\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the feature storage pipeline for carts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1742 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading the gt datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f3c07b149987>:51: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1m\u001b[1munsafe cast from Tuple(int64, float64, float64, float64, int64, int64, float64, float64, int64, float64, float64, int64, int64, int64, float64, float64, float64, float64, float64, float64, float64, float64, float64, int64, int64, int64, int32, int64, float64, float64, float64, float64, float64, float64, float64) to Tuple(bool, float64, float64, int64, int64, int64, float64, float64, int32, float32, float64, int32, float64, float64, float32, float32, float32, float32, float32, float32, float32, float32, float32, int32, int32, int32, int32, float32, float32, float32, float32, float32, float32, float32, float32). Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "  update_feature_vec(aid, features_tuple_arr, features_idx_map, \\\n",
      "<ipython-input-11-f3c07b149987>:51: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1m\u001b[1munsafe cast from Tuple(int64, float64, float64, float64, int64, int64, float64, float64, int64, int64, int64, int64, int64, int64, float64, float64, float64, float64, float64, float64, float64, float64, float64, bool, bool, bool, int32, int64, float64, float64, float64, int64, int64, int64, int64) to Tuple(bool, float64, float64, int64, int64, int64, float64, float64, int32, float32, float64, int32, float64, float64, float32, float32, float32, float32, float32, float32, float32, float32, float32, int32, int32, int32, int32, float32, float32, float32, float32, float32, float32, float32, float32). Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "  update_feature_vec(aid, features_tuple_arr, features_idx_map, \\\n",
      "<ipython-input-11-f3c07b149987>:83: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1m\u001b[1munsafe cast from Tuple(int64, float64, float64, float64, int64, int64, float64, float64, int64, float64, float64, int64, int64, int64, float64, float64, float64, float64, float64, float64, float64, float64, float64, bool, bool, bool, int32, int64, float64, float64, float64, int64, int64, int64, int64) to Tuple(bool, float64, float64, int64, int64, int64, float64, float64, int32, float32, float64, int32, float64, float64, float32, float32, float32, float32, float32, float32, float32, float32, float32, int32, int32, int32, int32, float32, float32, float32, float32, float32, float32, float32, float32). Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "  update_feature_vec(similar_item, features_tuple_arr, features_idx_map, \\\n",
      "  8%|▊         | 146/1742 [05:33<32:44:28, 73.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_0 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 291/1742 [09:45<18:32:45, 46.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_1 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 436/1742 [15:32<27:41:57, 76.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_2 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 581/1742 [19:05<11:45:59, 36.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_3 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 726/1742 [23:39<15:54:44, 56.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_4 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 871/1742 [26:53<7:38:28, 31.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_5 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1016/1742 [29:30<4:13:49, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_6 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1161/1742 [32:45<5:15:20, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_7 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1306/1742 [35:58<3:42:00, 30.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_8 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1451/1742 [39:12<2:16:28, 28.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_9 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1596/1742 [43:10<1:42:22, 42.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_10 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1741/1742 [46:00<00:23, 23.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_11 completes saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1742/1742 [46:01<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_batch_12 completes saving.\n",
      "CPU times: user 19min 49s, sys: 16min 34s, total: 36min 24s\n",
      "Wall time: 46min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_iuf_carts = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "features_all_sessions = [] # session, aid, feature tuple\n",
    "                          ## session, aid, feature tuple\n",
    "gc.collect()\n",
    "\n",
    "## Given there are 1783737 sessions in total, we separate them into K batches\n",
    "K = 12\n",
    "batch_size = 1783737 // K  ##  -> 148644 dealing with around 150k sessions per batch\n",
    "row_idx_cutoffs = [(len(df) - len(df_test)) + (1024 * 145) * i for i in range(1, K+3)]   ## batch process every 1024 * 145 rows\n",
    "# 145 -> 148644 // 1024  -> batch_size // PARALLEL\n",
    "\n",
    "feature_batch_id = 0\n",
    "## load important tables\n",
    "valid_gt_sessions, gt_labels = load_gt_tables(\"carts\")\n",
    "print(\"finish loading the gt datas\")\n",
    "\n",
    "for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "    start_row = row_idx\n",
    "    end_row = min(row_idx + PARALLEL, len(df))\n",
    "    rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "#     save_features_parallel(rows, aids, ops, ts, result_iuf_orders, simMatrices[\"iuf\"], np.array([2.0, 8.0, 6.0]), orders_features_save)  \n",
    "    ## run things in parallel\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        features_tuples_this_session = save_feature_single_session(session, starting_idx, length, start_time, aids, ops, ts, result_iuf_carts, simMatrices[\"iuf\"], item_total_likes, np.array([4.0, 2.0, 5.0]))\n",
    "        features_all_sessions.append(features_tuples_this_session)\n",
    "    \n",
    "    if (start_row in row_idx_cutoffs) or (end_row == len(df)):\n",
    "        ## save batch result\n",
    "        rawDf = pd.DataFrame({\"session\": result_iuf_carts.keys(), \"aids\": result_iuf_carts.values(), \"feature_tuple\": features_all_sessions})\n",
    "        batch_result = process_batch_pipeline(rawDf, valid_gt_sessions, gt_labels)\n",
    "        batch_result.to_parquet(f\"../../allData/features/cart_features_V5/batch_result_{feature_batch_id}.parquet\")\n",
    "        ## clean the memory for next batch\n",
    "        del batch_result, rawDf, features_all_sessions, result_iuf_carts\n",
    "        gc.collect()\n",
    "        ## progress update\n",
    "        print(f\"feature_batch_{feature_batch_id} completes saving.\")\n",
    "        feature_batch_id += 1\n",
    "        ## initiate the struct for new batch again\n",
    "        result_iuf_carts = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.types.int64[:])\n",
    "        features_all_sessions = []\n",
    "        \n",
    "    #break\n",
    "#     gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do same thing for carts, Draft from earlier, DEPRECATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1742 [00:00<?, ?it/s]<ipython-input-11-e41a977c9bca>:47: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1m\u001b[1munsafe cast from Tuple(int64, float64, float64, float64, int64, int64, float64) to Tuple(bool, float64, float64, int64, int64, int64, float64). Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "  update_feature_vec(aid, features_tuple_arr, features_idx_map, (1, seq_w, time_w, test_ops_weights[op], length, len(unique_aids), potential_to_recommend[aid]))\n",
      "100%|██████████| 1742/1742 [09:11<00:00,  3.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 18s, sys: 1min 35s, total: 5min 53s\n",
      "Wall time: 9min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# result_iuf_orders = nb.typed.Dict.empty(\n",
    "#     key_type = nb.types.int64,\n",
    "#     value_type = nb.types.int64[:])\n",
    "\n",
    "result_iuf_carts = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "# result_time_decay_clicks = nb.typed.Dict.empty(\n",
    "#     key_type = nb.types.int64,\n",
    "#     value_type = nb.types.int64[:])\n",
    "\n",
    "features_all_sessions = []\n",
    "gc.collect()\n",
    "\n",
    "for row_idx in tqdm(range(len(df) - len(df_test), len(df), PARALLEL)):\n",
    "    start_row = row_idx\n",
    "    end_row = min(row_idx + PARALLEL, len(df))\n",
    "    rows = df.iloc[start_row: end_row][['session', 'start_idx', 'total_action', 'session_start_time']].values\n",
    "#     save_features_parallel(rows, aids, ops, ts, result_iuf_orders, simMatrices[\"iuf\"], np.array([2.0, 8.0, 6.0]), orders_features_save)  \n",
    "    ## run things in parallel\n",
    "    for row_idx in nb.prange(len(rows)):\n",
    "        session, starting_idx, length, start_time = rows[row_idx]\n",
    "        features_tuples_this_session = save_feature_single_session(session, starting_idx, length, start_time, aids, ops, ts, result_iuf_carts, simMatrices[\"iuf\"], np.array([4.0, 2.0, 5.0]))\n",
    "        features_all_sessions.append(features_tuples_this_session)\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 26.8 s, total: 36.5 s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10031"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "## save the result as df \n",
    "features_save = pd.DataFrame({\"session\": result_iuf_carts.keys(), \"aids\": result_iuf_carts.values(), \"feature_tuple\": features_all_sessions})\n",
    "# features_save = features_save.set_index(['session']).apply(pd.Series.explode).reset_index()\n",
    "del features_all_sessions\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 1min 9s, total: 1min 27s\n",
      "Wall time: 5min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## A total of 569697 carts action that's predictable \n",
    "## get all valid sessions with carts actions\n",
    "## there are 150179 / 1783737 sessions have orders actions, 301057 / 1783737 have carts, 1737968 / 1783737 have clicks\n",
    "carts_labels = pd.read_json(\"../../allData/validationData/out_7day_test/test_labels.jsonl\", lines=True)\n",
    "carts_labels['aids'] = carts_labels[\"labels\"].apply(lambda x: x.get(\"carts\"))\n",
    "carts_labels = carts_labels[carts_labels.aids.notnull()]\n",
    "carts_labels = carts_labels.drop(\"labels\", axis = 1)\n",
    "## ========= special df to identify the unique session id to look at ================\n",
    "valid_cart_sessions = carts_labels.drop(\"aids\", axis = 1) \n",
    "## ========================================================================\n",
    "## keep go on for cart labels processing\n",
    "carts_labels = carts_labels.set_index(['session']).apply(pd.Series.explode).reset_index()\n",
    "carts_labels[\"gt\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join with features_save, now only cart_features in valid sessions are kept, and as expected 301057 sessions are the valid sessions to expand\n",
    "cart_features_valid_session = pd.merge(features_save, valid_cart_sessions, on=\"session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now explode the whole valid session aids, a total of 27168199 session - aid are served as the traini/val/test data for cart, \n",
    "## a total of 569697 correct guesses(not 100% included in the recall)\n",
    "cart_features_valid_session = cart_features_valid_session.set_index(['session']).apply(pd.Series.explode).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finally \n",
    "carts_full_df = pd.merge(cart_features_valid_session, carts_labels, on=[\"session\", \"aids\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ops_total\n"
     ]
    }
   ],
   "source": [
    "## open up the feature tuple \n",
    "carts_full_df[\"prev_int\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[0])\n",
    "carts_full_df[\"seq_w\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[1])\n",
    "carts_full_df[\"time_w\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[2])\n",
    "carts_full_df[\"ops_total\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[3])\n",
    "print(\"Done with ops_total\")\n",
    "carts_full_df[\"session_len\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[4])\n",
    "carts_full_df[\"session_unique_aid\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[5])\n",
    "carts_full_df[\"rank_score\"] = carts_full_df[\"feature_tuple\"].apply(lambda x: x[6])\n",
    "carts_full_df = carts_full_df.drop(\"feature_tuple\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aids</th>\n",
       "      <th>gt</th>\n",
       "      <th>prev_int</th>\n",
       "      <th>seq_w</th>\n",
       "      <th>time_w</th>\n",
       "      <th>ops_total</th>\n",
       "      <th>session_len</th>\n",
       "      <th>session_unique_aid</th>\n",
       "      <th>rank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>11830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.231144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.737330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1732105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.773733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>588923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.466177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>571762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.752040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098528</td>\n",
       "      <td>884502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231144</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session     aids  gt  prev_int     seq_w  time_w  ops_total  session_len  \\\n",
       "0  11098528    11830 NaN      True  0.231144     3.0          4            1   \n",
       "1  11098528  1732105 NaN     False  0.231144     3.0          4            1   \n",
       "2  11098528   588923 NaN     False  0.231144     3.0          4            1   \n",
       "3  11098528   571762 NaN     False  0.231144     3.0          4            1   \n",
       "4  11098528   884502 NaN     False  0.231144     3.0          4            1   \n",
       "\n",
       "   session_unique_aid  rank_score  \n",
       "0                   1   27.737330  \n",
       "1                   1    2.773733  \n",
       "2                   1    1.466177  \n",
       "3                   1    0.752040  \n",
       "4                   1    0.709451  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carts_full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "carts_full_df.to_parquet(\"../../allData/features/carts_features_100_per_session_V3_opwFix.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # final_df[\"prev_int\"] = final_df[\"feature_tuple\"].apply(lambda x: x[0])\n",
    "    # final_df[\"seq_w_total\"] = final_df[\"feature_tuple\"].apply(lambda x: x[1])\n",
    "    # final_df[\"time_w_total\"] = final_df[\"feature_tuple\"].apply(lambda x: x[2])\n",
    "    # final_df[\"ops_total\"] = final_df[\"feature_tuple\"].apply(lambda x: x[3])\n",
    "    # final_df[\"session_len\"] = final_df[\"feature_tuple\"].apply(lambda x: x[4])\n",
    "    # final_df[\"session_unique_aid\"] = final_df[\"feature_tuple\"].apply(lambda x: x[5])\n",
    "    # final_df[\"cf_score\"] = final_df[\"feature_tuple\"].apply(lambda x: x[6])\n",
    "    # final_df[\"item_total_like\"] = final_df[\"feature_tuple\"].apply(lambda x: x[7])\n",
    "    # final_df[\"num_reference_time\"] = final_df[\"feature_tuple\"].apply(lambda x: x[8])\n",
    "    # final_df[\"max_sim_score\"] = final_df[\"feature_tuple\"].apply(lambda x: x[9])\n",
    "    # final_df[\"mean_sim_score\"] = final_df[\"feature_tuple\"].apply(lambda x: x[10])\n",
    "    # final_df[\"num_interact\"] = final_df[\"feature_tuple\"].apply(lambda x: x[11])\n",
    "    # final_df[\"time_span\"] = final_df[\"feature_tuple\"].apply(lambda x: x[12])\n",
    "    # final_df[\"action_recency\"] = final_df[\"feature_tuple\"].apply(lambda x: x[13])\n",
    "    # final_df[\"seq_w_max\"] = final_df[\"feature_tuple\"].apply(lambda x: x[14])\n",
    "    # final_df[\"seq_w_mean\"] = final_df[\"feature_tuple\"].apply(lambda x: x[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given there are 1783737 sessions in total, we separate them into K batches\n",
    "K = 6\n",
    "batch_size = 1783737 // K  ##  -> 297289 ~ 1024 * 290 dealing with around 30k sessions per batch\n",
    "row_idx_cutoffs = [(len(df) - len(df_test)) + (1024 * 290)* i for i in range(1, 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant change to feature storage, \n",
    "using Session Cache instead of dynamic save\n",
    "### Intended structure\n",
    "For each session, a structure of following will be created   \n",
    "session_ts_cache: {  \n",
    "                   aid1: [ts_1, ts_2, ...],   \n",
    "                   aid2: [ts, ......],  \n",
    "                   ..........  \n",
    "                   }\n",
    "\n",
    "session_ops_cache: {\n",
    "                  aid1: [ops_1, ops_2, ...] \n",
    "}\n",
    "\n",
    "session_simScore_cache: {\n",
    "                 aid1: []\n",
    "}\n",
    "\n",
    "session_CFIncre_cache: {\n",
    "                 aid1: []\n",
    "}\n",
    "\n",
    "session_seqW_cache: {\n",
    "    aid1\n",
    "}\n",
    "\n",
    "session_timeW_cache: {\n",
    "\n",
    "}\n",
    "\n",
    "session_rawSeqOrder_cache: {\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>total_action</th>\n",
       "      <th>session_start_time</th>\n",
       "      <th>session_end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>6</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661120532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531</td>\n",
       "      <td>24</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532</td>\n",
       "      <td>2</td>\n",
       "      <td>1661119201</td>\n",
       "      <td>1661119996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783732</th>\n",
       "      <td>12899774</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723968</td>\n",
       "      <td>1661723968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783733</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723970</td>\n",
       "      <td>1661723970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783734</th>\n",
       "      <td>12899776</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723972</td>\n",
       "      <td>1661723972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783735</th>\n",
       "      <td>12899777</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723976</td>\n",
       "      <td>1661723976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783736</th>\n",
       "      <td>12899778</td>\n",
       "      <td>1</td>\n",
       "      <td>1661723983</td>\n",
       "      <td>1661723983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783737 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session  total_action  session_start_time  session_end_time\n",
       "0        11098528             1          1661119200        1661119200\n",
       "1        11098529             1          1661119200        1661119200\n",
       "2        11098530             6          1661119200        1661120532\n",
       "3        11098531            24          1661119200        1661119746\n",
       "4        11098532             2          1661119201        1661119996\n",
       "...           ...           ...                 ...               ...\n",
       "1783732  12899774             1          1661723968        1661723968\n",
       "1783733  12899775             1          1661723970        1661723970\n",
       "1783734  12899776             1          1661723972        1661723972\n",
       "1783735  12899777             1          1661723976        1661723976\n",
       "1783736  12899778             1          1661723983        1661723983\n",
       "\n",
       "[1783737 rows x 4 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test interface\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>total_action</th>\n",
       "      <th>session_start_time</th>\n",
       "      <th>session_end_time</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10584520</th>\n",
       "      <td>11098531</td>\n",
       "      <td>24</td>\n",
       "      <td>1661119200</td>\n",
       "      <td>1661119746</td>\n",
       "      <td>163441177</td>\n",
       "      <td>1661119746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           session  total_action  session_start_time  session_end_time  \\\n",
       "10584520  11098531            24          1661119200        1661119746   \n",
       "\n",
       "          start_idx    end_time  \n",
       "10584520  163441177  1661119746  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.session == 11098531]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def save_feature_single_session_by_caching(session, starting_idx, length, start_time, aids, ops, ts, result, full_sim_matrix, item_total_likes, test_ops_weights):\n",
    "\n",
    "    NOW_TIME = ts[-1] ## ts of latest avaiable action\n",
    "    PREV_INTERACT_BONUS = 20\n",
    "    NEARBY_ACTION_BONUS = 1.5\n",
    "    \n",
    "    ending_idx = starting_idx + length \n",
    "    end_time = ts[ending_idx - 1]\n",
    "    time_span = end_time - start_time\n",
    "    \n",
    "    candidates = aids[starting_idx: ending_idx][::-1]\n",
    "    candidates_ops = ops[starting_idx: ending_idx][::-1]\n",
    "    \n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "    \n",
    "    ## get unique aid of each session \n",
    "    unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "    for a in candidates:\n",
    "        unique_aids[a] = 0\n",
    "    \n",
    "    ## Sequence weight to all the candidates, from near to far \n",
    "    sequence_weight = np.power(2, np.linspace(0.3, 1, len(candidates)))[::-1] - 1\n",
    "\n",
    "    raw_sequence = np.arange(1, len(candidates) + 1)\n",
    "    \n",
    "    ## Time weight of all candidates, from near to far\n",
    "    time_weights = []\n",
    "    time_lapse = end_time - start_time + 1  ## +1 to avoid zero\n",
    "    for idx in range(starting_idx, ending_idx):\n",
    "        if end_time - ts[idx] < 2 * 60 * 60:   ## apply nearby action bonus\n",
    "            time_weight = (1 + 0.5 ** ((end_time - ts[idx])/time_lapse)) * NEARBY_ACTION_BONUS\n",
    "        else:\n",
    "            time_weight = 1 + 0.5 ** ((end_time - ts[idx])/time_lapse)\n",
    "        time_weights.append(time_weight)\n",
    "    time_weights = time_weights[::-1]\n",
    "    \n",
    "    ## feature vector template: [aid: <is_prev_int, seq_w, time_w, associated_action, session_len,.. >]\n",
    "    features_tuple_arr = nb.typed.List()\n",
    "    features_tuple_arr.append(FEATURE_TUPLE_TEMPLATE)\n",
    "    features_idx_map = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.int64)\n",
    "\n",
    "    ## initiate the caches for the features\n",
    "    ts_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    ops_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))    #value_type = nb.types.float64[:])\n",
    "    simScore_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    cfIncre_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    seqW_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    timeW_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    actionW_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "    raw_seqOrder_cache = nb.typed.Dict.empty(key_type = nb.types.int64, value_type=np.array([np.float64(0.0) for _ in range(0)]))\n",
    "\n",
    "    helper_idx = starting_idx\n",
    "    ## making inference\n",
    "    if len(unique_aids) >= 20:  \n",
    "        for aid, op, seq_w, raw_seq_order, time_w in zip(candidates, candidates_ops, sequence_weight, raw_sequence, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "                ## init all cache obj\n",
    "                ts_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                ops_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                simScore_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                cfIncre_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                seqW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                timeW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                actionW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                raw_seqOrder_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "            ## caculate scores\n",
    "            cf_incre = seq_w * time_w * test_ops_weights[op]\n",
    "            potential_to_recommend[aid] += cf_incre #* PREV_INTERACT_BONUS\n",
    "            ## append features\n",
    "            ts_cache[aid] = np.append(ts_cache[aid], ts[helper_idx])\n",
    "            ops_cache[aid] = np.append(ops_cache[aid], op)\n",
    "            simScore_cache[aid] = np.append(simScore_cache[aid], 1)\n",
    "            cfIncre_cache[aid] = np.append(cfIncre_cache[aid], cf_incre)\n",
    "            seqW_cache[aid] = np.append(seqW_cache[aid], seq_w)\n",
    "            timeW_cache[aid] = np.append(timeW_cache[aid], time_w)\n",
    "            actionW_cache[aid] = np.append(actionW_cache[aid], test_ops_weights[op])\n",
    "            raw_seqOrder_cache[aid] = np.append(raw_seqOrder_cache[aid], raw_seq_order)\n",
    "            \n",
    "            \n",
    "            helper_idx += 1\n",
    "    else:   ## otherwise, fill the rest with similar items.\n",
    "        for aid, op, seq_w, raw_seq_order, time_w in zip(candidates, candidates_ops, sequence_weight, raw_sequence, time_weights):\n",
    "            if aid not in potential_to_recommend:\n",
    "                potential_to_recommend[aid] = 0\n",
    "                ## init all cache obj\n",
    "                ts_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                ops_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                simScore_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                cfIncre_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                seqW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                timeW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                actionW_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "                raw_seqOrder_cache[aid] = np.array([np.float64(0) for _ in range(0)])\n",
    "            ## get the scores\n",
    "            cf_incre = seq_w * time_w * test_ops_weights[op] * PREV_INTERACT_BONUS\n",
    "            potential_to_recommend[aid] += cf_incre\n",
    "            ## append features\n",
    "            ts_cache[aid] = np.append(ts_cache[aid], ts[helper_idx])\n",
    "            ops_cache[aid] = np.append(ops_cache[aid], op)\n",
    "            simScore_cache[aid] = np.append(simScore_cache[aid], 1)\n",
    "            cfIncre_cache[aid] = np.append(cfIncre_cache[aid], cf_incre)\n",
    "            seqW_cache[aid] = np.append(seqW_cache[aid], seq_w)\n",
    "            timeW_cache[aid] = np.append(timeW_cache[aid], time_w)\n",
    "            actionW_cache[aid] = np.append(actionW_cache[aid], test_ops_weights[op])\n",
    "            raw_seqOrder_cache[aid] = np.append(raw_seqOrder_cache[aid], raw_seq_order)\n",
    "            ## adding the similar items, if full_sim_matrix don't have such record, skip. \n",
    "            if aid not in full_sim_matrix:\n",
    "                continue\n",
    "            for similar_item in full_sim_matrix[aid]:\n",
    "                ## if sim_item is in candidates, would be included above anyways, skip \n",
    "                if similar_item in candidates:\n",
    "                    continue\n",
    "                if similar_item not in potential_to_recommend:\n",
    "                    potential_to_recommend[similar_item] = 0\n",
    "                    ## init all cache obj\n",
    "                    ts_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    ops_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    simScore_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    cfIncre_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    seqW_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    timeW_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    actionW_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                    raw_seqOrder_cache[similar_item] = np.array([np.float64(0) for _ in range(0)])\n",
    "                \n",
    "                cf_incre = seq_w * time_w * test_ops_weights[op] * full_sim_matrix[aid][similar_item]\n",
    "                potential_to_recommend[similar_item] += cf_incre  ## no PREV_INTERACT_BONUS as expected, replaced with sim_matrix scores\n",
    "                ## append features\n",
    "                ops_cache[similar_item] = np.append(ops_cache[similar_item], op)\n",
    "                ts_cache[similar_item] = np.append(ts_cache[similar_item], ts[helper_idx])\n",
    "                ops_cache[similar_item] = np.append(ops_cache[similar_item], op)\n",
    "                simScore_cache[similar_item] = np.append(simScore_cache[similar_item], 1)\n",
    "                cfIncre_cache[similar_item] = np.append(cfIncre_cache[similar_item], cf_incre)\n",
    "                seqW_cache[similar_item] = np.append(seqW_cache[similar_item], seq_w)\n",
    "                timeW_cache[similar_item] = np.append(timeW_cache[similar_item], time_w)\n",
    "                actionW_cache[similar_item] = np.append(actionW_cache[similar_item], test_ops_weights[op])\n",
    "                raw_seqOrder_cache[similar_item] = np.append(raw_seqOrder_cache[similar_item], raw_seq_order)\n",
    "                \n",
    "            helper_idx += 1\n",
    "\n",
    "    result[session] = np.array(heap_topk_return_list(potential_to_recommend, 100))  ## Take top 100 for validation runs. \n",
    "    \n",
    "#     feature_tuples_this_session = []\n",
    "#     for aid in result[session]:\n",
    "# #         features_save[(session, aid)] = features_tuple_arr[features_idx_map[aid]]\n",
    "#         feature_tuples_this_session.append(features_tuple_arr[features_idx_map[aid]])\n",
    "    \n",
    "    return ops_cache, raw_seqOrder_cache, seqW_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_result = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "test_cache, test1_cache, test2_cache = save_feature_single_session_by_caching(11098531, 163441177, 24, 1661119200, aids, ops, ts, pseudo_result , simMatrices[\"iuf\"], item_total_likes, np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cache[653835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cache[653835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 11., 12., 13., 14.,\n",
       "       15., 16., 17., 18., 20., 21., 22., 24.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1_cache[653835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.95825035, 0.91737222, 0.87734741, 0.83815811,\n",
       "       0.79978689, 0.76221665, 0.72543069, 0.68941263, 0.61961642,\n",
       "       0.58580721, 0.55270376, 0.52029135, 0.48855553, 0.4574822 ,\n",
       "       0.42705751, 0.39726794, 0.33954136, 0.31157867, 0.2841997 ,\n",
       "       0.23114441])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2_cache[653835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for aid in test_cache:\n",
    "    print(test_cache[aid])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 7, 6, 5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 10)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.88230446, 0.77153504, 0.66728415, 0.5691682 ,\n",
       "       0.47682615, 0.38991822, 0.30812463, 0.23114441])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(2, np.linspace(0.3, 1, 9))[::-1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictType[int64,array(int64, 1d, A)]<iv=None>({123: [ 234 4343]})"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "test[123] = np.array([234, 4343])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_cache = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int32, \n",
    "    value_type = nb.types.float32[:])\n",
    "ops_cache[123] = np.array([np.float32(0.0) for _ in range(0)], dtype=np.float32) # np.array(dtype=np.float32)\n",
    "ops_cache[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops_cache[123] = np.array(np.append(ops_cache[123], 2.0), dtype=np.float32)\n",
    "ops_cache[123] = np.array(np.append(ops_cache[123], 8.0), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 8.], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_cache[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_cache[123][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ops_cache[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ops_cache[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff58dbd0ec383761c792d0b6d4f0a9690d9c9b1bec648659fb440990235d5b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
