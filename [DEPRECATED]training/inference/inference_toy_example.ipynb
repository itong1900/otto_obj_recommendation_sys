{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Function for inference pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## steps to make inferences\n",
    "## 1. read in a test set row, look at its aids and ops\n",
    "## 2. give time weight and seq weight for each aid it has interaction with\n",
    "## 3. based on the aids, search the similar items of aids in the fullSimMatrix.\n",
    "## 4. get all the sim scores and combine with the seq weights and time weight found in step #2\n",
    "## 5. Find the top 20 items of each user in step 4, use heap_topk to reduce memory overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullSimMatrix = nb.typed.Dict.empty(\n",
    "        key_type = nb.types.int64,\n",
    "        value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "\n",
    "inner_dict_1 = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "inner_dict_1[2] = 100.0\n",
    "inner_dict_1[4] = 120.0\n",
    "inner_dict_1[6] = 80.0\n",
    "inner_dict_1[8] = 90.0\n",
    "\n",
    "inner_dict_3 = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "inner_dict_3[2] = 102.0\n",
    "inner_dict_3[4] = 800.0\n",
    "inner_dict_3[6] = 400.0\n",
    "inner_dict_3[8] = 600.0\n",
    "\n",
    "itemid_set1 = [1, 3]  # 5, 7, 9, 11]\n",
    "dict_set = [inner_dict_1, inner_dict_3]\n",
    "\n",
    "for idx, item1 in enumerate(itemid_set1):\n",
    "    fullSimMatrix[item1] = dict_set[idx] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictType[int64,DictType[int64,float64]<iv=None>]<iv=None>({1: {2: 100.0, 4: 120.0, 6: 80.0, 8: 90.0}, 3: {2: 102.0, 4: 800.0, 6: 400.0, 8: 600.0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullSimMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create test set data\n",
    "aids = [1, 2, 2, 1]\n",
    "ops = [0, 0, 1, 0]\n",
    "length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True)\n",
    "def heap_topk(item_cnt_dict, cap):\n",
    "    \"\"\"\n",
    "    get the top cap(k) elements of the cnt dict based on value, using a min-heap structure\n",
    "    \"\"\"\n",
    "    q = [(np.float64(0), np.int64(0)) for _ in range(0)]  ## generate empty queue to implement a heap, \n",
    "    for item_ref, sim_score in item_cnt_dict.items():   ## read in the dict in heap structure\n",
    "        heapq.heappush(q, (sim_score, item_ref))   ## push the <sim_score, item_ref_id> pair into min-heap, using sim_score for order\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "            \n",
    "    res = [heapq.heappop(q)[1] for _ in range(len(q))][::-1]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def inference_single_session(candidate_aids, ops, result, full_sim_matrix, test_ops_weights):\n",
    "    ## 1. read in a test set row, look at its aids and ops\n",
    "    ## 2. give time weight and seq weight for each aid it has interaction with, \n",
    "    ## in other words, the value of unique_aids_weights shows how important the action is,\n",
    "\n",
    "    ## record all potential aid that might be relevant\n",
    "    potential_to_recommend = nb.typed.Dict.empty(key_type=nb.types.int64, value_type=nb.types.float64)\n",
    "    for idx, candidate in enumerate(candidate_aids):\n",
    "        action_realtime_weight = test_ops_weights[ops[idx]]  ## replace by some helper function that define the importance of an action, given by ts, ops, seq etc\n",
    "        \n",
    "        ## load the potential items to recommend, ## 3. based on the aids, search the similar items of aids in the fullSimMatrix.\n",
    "        for similar_item in full_sim_matrix[candidate]:\n",
    "            if similar_item not in potential_to_recommend:\n",
    "                potential_to_recommend[similar_item] = 0\n",
    "            ## step 4\n",
    "            potential_to_recommend[similar_item] += full_sim_matrix[candidate][similar_item] * action_realtime_weight\n",
    "        \n",
    "    ## step 5, get the top 20 of potential_to_recommend, and store it as a list and save it in result. \n",
    "    result[0] = heap_topk(potential_to_recommend, 2)  ## TODO: replace with result[session_id] = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itong1900/opt/anaconda3/lib/python3.8/site-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'candidate_aids' of function 'inference_single_session'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"<ipython-input-31-5009091cf0bf>\", line 2:\u001b[0m\n",
      "\u001b[1m@nb.jit(nopython=True)\n",
      "\u001b[1mdef inference_single_session(candidate_aids, ops, result, full_sim_matrix, test_ops_weights):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
      "/Users/itong1900/opt/anaconda3/lib/python3.8/site-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'ops' of function 'inference_single_session'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"<ipython-input-31-5009091cf0bf>\", line 2:\u001b[0m\n",
      "\u001b[1m@nb.jit(nopython=True)\n",
      "\u001b[1mdef inference_single_session(candidate_aids, ops, result, full_sim_matrix, test_ops_weights):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    }
   ],
   "source": [
    "result_inf = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "\n",
    "inference_single_session(aids, ops, result_inf, fullSimMatrix, np.array([1.0, 6.0, 3.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 6., 3.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.0, 6.0, 3.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff58dbd0ec383761c792d0b6d4f0a9690d9c9b1bec648659fb440990235d5b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
